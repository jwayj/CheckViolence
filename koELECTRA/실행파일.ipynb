{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896d396c-2b72-4fef-9d4a-2a1f731cba12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n",
      "max_length : 128\n",
      "[train]: 로드 중 파일: ./data/train.csv\n",
      "[train]: 총 1개의 파일에서 365,500개의 데이터를 성공적으로 병합했습니다.\n",
      "[train]: 원본 데이터 365,500개를 10,000개로 샘플링합니다.\n",
      "Train : 10000\n",
      "[valid]: 로드 중 파일: ./data/val.csv\n",
      "[valid]: 총 1개의 파일에서 40,612개의 데이터를 성공적으로 병합했습니다.\n",
      "Valid : 40612\n",
      "[test]: 로드 중 파일: ./data/test.csv\n",
      "[test]: 총 1개의 파일에서 44,998개의 데이터를 성공적으로 병합했습니다.\n",
      "Test : 44998\n",
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd63dfc1c56f4408824d852e8e20b4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/467 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af3c22ad85241ed80c4b3b14c1d1f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2323b247445d48619fc021d027c1abae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a58e74d4a94453985ff6ed01eeec201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2e9cdcf8884eebb730f2baaeb43470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraTokenizer(name_or_path='monologg/koelectra-base-discriminator', vocab_size=32200, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n",
      "The KOELECTRA model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "electra.embeddings.word_embeddings.weight               (32200, 768)\n",
      "electra.embeddings.position_embeddings.weight             (512, 768)\n",
      "electra.embeddings.token_type_embeddings.weight             (2, 768)\n",
      "electra.embeddings.LayerNorm.weight                           (768,)\n",
      "electra.embeddings.LayerNorm.bias                             (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "electra.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
      "electra.encoder.layer.0.attention.self.query.bias             (768,)\n",
      "electra.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
      "electra.encoder.layer.0.attention.self.key.bias               (768,)\n",
      "electra.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
      "electra.encoder.layer.0.attention.self.value.bias             (768,)\n",
      "electra.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
      "electra.encoder.layer.0.attention.output.dense.bias           (768,)\n",
      "electra.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
      "electra.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
      "electra.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
      "electra.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
      "electra.encoder.layer.0.output.dense.weight              (768, 3072)\n",
      "electra.encoder.layer.0.output.dense.bias                     (768,)\n",
      "electra.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
      "electra.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "classifier.dense.weight                                   (768, 768)\n",
      "classifier.dense.bias                                         (768,)\n",
      "classifier.out_proj.weight                                  (2, 768)\n",
      "classifier.out_proj.bias                                        (2,)\n",
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    50  of    313.    Elapsed: 0:00:11.\n",
      "  Batch   100  of    313.    Elapsed: 0:00:23.\n",
      "  Batch   150  of    313.    Elapsed: 0:00:34.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:46.\n",
      "  Batch   250  of    313.    Elapsed: 0:00:58.\n",
      "  Batch   300  of    313.    Elapsed: 0:01:10.\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:01:13\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation Loss: 0.44\n",
      "  Validation took: 0:01:39\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    50  of    313.    Elapsed: 0:00:12.\n",
      "  Batch   100  of    313.    Elapsed: 0:00:24.\n",
      "  Batch   150  of    313.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    313.    Elapsed: 0:00:49.\n",
      "  Batch   250  of    313.    Elapsed: 0:01:01.\n",
      "  Batch   300  of    313.    Elapsed: 0:01:13.\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epcoh took: 0:01:17\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.81\n",
      "  Validation Loss: 0.45\n",
      "  Validation took: 0:01:42\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:05:50 (h:mm:ss)\n",
      "Predicting labels for 1,407 total test sentences...\n",
      "\n",
      "--- [전체 데이터셋] 테스트 결과 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.78      0.89      0.83     18987\n",
      " 비도덕성 있음 (1)       0.91      0.81      0.86     26011\n",
      "\n",
      "    accuracy                           0.84     44998\n",
      "   macro avg       0.84      0.85      0.84     44998\n",
      "weighted avg       0.85      0.84      0.85     44998\n",
      "\n",
      "    DONE (Total Test).\n",
      "\n",
      "\n",
      "--- [유형별 상세 테스트 결과] ---\n",
      "\n",
      "--- TEST 데이터를 모든 유형을 기준으로 분리 중... ---\n",
      "  - 유형: CENSURE              | 샘플 수: 19,866\n",
      "  - 유형: ABUSE                | 샘플 수: 1,474\n",
      "  - 유형: HATE                 | 샘플 수: 9,222\n",
      "  - 유형: VIOLENCE             | 샘플 수: 2,167\n",
      "  - 유형: CRIME                | 샘플 수: 1,075\n",
      "  - 유형: SEXUAL               | 샘플 수: 2,737\n",
      "  - 유형: DISCRIMINATION       | 샘플 수: 2,664\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: CENSURE ---\n",
      "총 샘플 수: 19,866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.83      0.91     19866\n",
      "\n",
      "    accuracy                           0.83     19866\n",
      "   macro avg       0.50      0.42      0.45     19866\n",
      "weighted avg       1.00      0.83      0.91     19866\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: ABUSE ---\n",
      "총 샘플 수: 1,474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.88      0.94      1474\n",
      "\n",
      "    accuracy                           0.88      1474\n",
      "   macro avg       0.50      0.44      0.47      1474\n",
      "weighted avg       1.00      0.88      0.94      1474\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: HATE ---\n",
      "총 샘플 수: 9,222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.87      0.93      9222\n",
      "\n",
      "    accuracy                           0.87      9222\n",
      "   macro avg       0.50      0.44      0.47      9222\n",
      "weighted avg       1.00      0.87      0.93      9222\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: VIOLENCE ---\n",
      "총 샘플 수: 2,167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.89      0.94      2167\n",
      "\n",
      "    accuracy                           0.89      2167\n",
      "   macro avg       0.50      0.45      0.47      2167\n",
      "weighted avg       1.00      0.89      0.94      2167\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: CRIME ---\n",
      "총 샘플 수: 1,075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.69      0.82      1075\n",
      "\n",
      "    accuracy                           0.69      1075\n",
      "   macro avg       0.50      0.35      0.41      1075\n",
      "weighted avg       1.00      0.69      0.82      1075\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: SEXUAL ---\n",
      "총 샘플 수: 2,737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.74      0.85      2737\n",
      "\n",
      "    accuracy                           0.74      2737\n",
      "   macro avg       0.50      0.37      0.43      2737\n",
      "weighted avg       1.00      0.74      0.85      2737\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: DISCRIMINATION ---\n",
      "총 샘플 수: 2,664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.80      0.89      2664\n",
      "\n",
      "    accuracy                           0.80      2664\n",
      "   macro avg       0.50      0.40      0.45      2664\n",
      "weighted avg       1.00      0.80      0.89      2664\n",
      "\n",
      "\n",
      "--- 유형별 상세 테스트 종료 ---\n",
      "Saving model to ./model_checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -lcufile\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'ElectraTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./model_checkpoint\n",
      "'이런건 걍 돈없고 멍청한 전라도 여자들 겨냥한 상술이지' 은/는 폭력성이 포함된 문장입니다\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "\n",
    "from dataloader import Dataset\n",
    "from model import Models\n",
    "from transformers import BertTokenizer\n",
    "from utils import split_sentence\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def file_upload():\n",
    "    return render_template('load_file.html')\n",
    "    \n",
    "@app.route('/isViolence', methods = ['POST', 'GET'])\n",
    "def Predict():\n",
    "    if request.method == 'POST':\n",
    "        input_text = request.files['파일'].read().decode('utf-8') # 파일 불러오기\n",
    "        input_text = input_text.split('\\r\\n')\n",
    "        \n",
    "        if input_text == None:\n",
    "            return render_template('isViolence.html', Output = '')\n",
    "\n",
    "        sentences = split_sentence(input_text)  # 채팅 목록을 문장 단위로 분리\n",
    "        # print(sentences)\n",
    "        result = 0\n",
    "        for i, sentence in enumerate(sentences[:10000]):\n",
    "            if (i+1) % 1000 == 0:\n",
    "                print(f\"{i+1}번째 실행 중...\")\n",
    "            result += model.inference(sentence[-1])[1]\n",
    "        \n",
    "        ModelOutput = f\"해당 채팅방의 폭력성 대화 비율은 {round((result / len(sentences)) * 100, 2)}% 입니다\"\n",
    "        print(ModelOutput)\n",
    "        return render_template('isViolence.html', Output = ModelOutput)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    train_file_path = './data/train.csv'\n",
    "    valid_file_path = './data/val.csv'\n",
    "    test_file_path = './data/test.csv' \n",
    "    model_save_dir = './model_checkpoint'       # 모델 저장 디렉토리 경로\n",
    "    model_load_dir = './model_checkpoint'       # 모델 불러오기 디렉토리 경로\n",
    "\n",
    "    TRAIN_DATA_LIMIT = 10000\n",
    "\n",
    "    # # 1. 단일 Dataset 인스턴스 생성 및 데이터 로드\n",
    "    dataset = Dataset()\n",
    "    dataset.set_dataset('train', file_path=train_file_path, max_rows=TRAIN_DATA_LIMIT)\n",
    "    dataset.set_dataset('valid', file_path=valid_file_path)\n",
    "    dataset.set_dataset('test', file_path=test_file_path)\n",
    "\n",
    "    # # 2. Models 인스턴스 생성 및 Dataset 연결\n",
    "    # Models 인스턴스를 만들 때, dataset 객체를 인수로 전달합니다.\n",
    "    model = Models('koelectra', num_labels = 2, dataset_instance=dataset) \n",
    "    \n",
    "    # # 3. 모델 정의 및 토크나이저 설정\n",
    "    # model.BERT()를 호출하여 모델을 생성하고, 반환된 토크나이저를 dataset에 설정합니다.\n",
    "    tokenizer_for_training = model.BERT()  \n",
    "    dataset.set_tokenizer(tokenizer_for_training)\n",
    "    \n",
    "    print(dataset.get_tokenizer())\n",
    "    \n",
    "    # # 4. 데이터 로더 생성 (이제 올바른 토크나이저를 사용)\n",
    "    train, valid, test = dataset.get_dataloader()  \n",
    "    \n",
    "    model.about_model()\n",
    "    model.train(train, valid, epochs = 2, project_title=None) \n",
    "    model.test(test)\n",
    "    model.save_model(model_save_dir)\n",
    "\n",
    "    # # 5. 추론 및 웹 서버용 모델 로드 (새로운 인스턴스 생성 및 로드)\n",
    "    # 추론용 모델도 동일한 dataset 인스턴스를 사용하도록 연결\n",
    "    web_model = Models('koelectra', num_labels = 2, dataset_instance=dataset)\n",
    "    web_model.load_model(load_dir_path=model_load_dir)\n",
    "    \n",
    "    # # 6. 단일 문장 추론 테스트\n",
    "    sentence, prediction = web_model.inference('이런건 걍 돈없고 멍청한 전라도 여자들 겨냥한 상술이지')\n",
    "    print(f\"'{sentence}' 은/는 폭력성이 포함된 문장입니다\" if prediction == 1 else f\"'{sentence}' 은/는 폭력성이 포함되지 않은 문장입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d922900d-cd05-4fad-8a42-2515c97cec0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n",
      "max_length : 128\n",
      "[train]: 로드 중 파일: ./data/train.csv\n",
      "[train]: 총 1개의 파일에서 365,500개의 데이터를 성공적으로 병합했습니다.\n",
      "[train]: 원본 데이터 365,500개를 50,000개로 샘플링합니다.\n",
      "Train : 50000\n",
      "[valid]: 로드 중 파일: ./data/val.csv\n",
      "[valid]: 총 1개의 파일에서 40,612개의 데이터를 성공적으로 병합했습니다.\n",
      "Valid : 40612\n",
      "[test]: 로드 중 파일: ./data/test.csv\n",
      "[test]: 총 1개의 파일에서 44,998개의 데이터를 성공적으로 병합했습니다.\n",
      "Test : 44998\n",
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraTokenizer(name_or_path='monologg/koelectra-base-discriminator', vocab_size=32200, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n",
      "The KOELECTRA model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "electra.embeddings.word_embeddings.weight               (32200, 768)\n",
      "electra.embeddings.position_embeddings.weight             (512, 768)\n",
      "electra.embeddings.token_type_embeddings.weight             (2, 768)\n",
      "electra.embeddings.LayerNorm.weight                           (768,)\n",
      "electra.embeddings.LayerNorm.bias                             (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "electra.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
      "electra.encoder.layer.0.attention.self.query.bias             (768,)\n",
      "electra.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
      "electra.encoder.layer.0.attention.self.key.bias               (768,)\n",
      "electra.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
      "electra.encoder.layer.0.attention.self.value.bias             (768,)\n",
      "electra.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
      "electra.encoder.layer.0.attention.output.dense.bias           (768,)\n",
      "electra.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
      "electra.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
      "electra.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
      "electra.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
      "electra.encoder.layer.0.output.dense.weight              (768, 3072)\n",
      "electra.encoder.layer.0.output.dense.bias                     (768,)\n",
      "electra.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
      "electra.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "classifier.dense.weight                                   (768, 768)\n",
      "classifier.dense.bias                                         (768,)\n",
      "classifier.out_proj.weight                                  (2, 768)\n",
      "classifier.out_proj.bias                                        (2,)\n",
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    50  of  1,563.    Elapsed: 0:00:12.\n",
      "  Batch   100  of  1,563.    Elapsed: 0:00:24.\n",
      "  Batch   150  of  1,563.    Elapsed: 0:00:36.\n",
      "  Batch   200  of  1,563.    Elapsed: 0:00:48.\n",
      "  Batch   250  of  1,563.    Elapsed: 0:01:00.\n",
      "  Batch   300  of  1,563.    Elapsed: 0:01:12.\n",
      "  Batch   350  of  1,563.    Elapsed: 0:01:25.\n",
      "  Batch   400  of  1,563.    Elapsed: 0:01:37.\n",
      "  Batch   450  of  1,563.    Elapsed: 0:01:49.\n",
      "  Batch   500  of  1,563.    Elapsed: 0:02:02.\n",
      "  Batch   550  of  1,563.    Elapsed: 0:02:14.\n",
      "  Batch   600  of  1,563.    Elapsed: 0:02:26.\n",
      "  Batch   650  of  1,563.    Elapsed: 0:02:39.\n",
      "  Batch   700  of  1,563.    Elapsed: 0:02:51.\n",
      "  Batch   750  of  1,563.    Elapsed: 0:03:04.\n",
      "  Batch   800  of  1,563.    Elapsed: 0:03:16.\n",
      "  Batch   850  of  1,563.    Elapsed: 0:03:29.\n",
      "  Batch   900  of  1,563.    Elapsed: 0:03:41.\n",
      "  Batch   950  of  1,563.    Elapsed: 0:03:53.\n",
      "  Batch 1,000  of  1,563.    Elapsed: 0:04:06.\n",
      "  Batch 1,050  of  1,563.    Elapsed: 0:04:18.\n",
      "  Batch 1,100  of  1,563.    Elapsed: 0:04:31.\n",
      "  Batch 1,150  of  1,563.    Elapsed: 0:04:43.\n",
      "  Batch 1,200  of  1,563.    Elapsed: 0:04:56.\n",
      "  Batch 1,250  of  1,563.    Elapsed: 0:05:08.\n",
      "  Batch 1,300  of  1,563.    Elapsed: 0:05:21.\n",
      "  Batch 1,350  of  1,563.    Elapsed: 0:05:33.\n",
      "  Batch 1,400  of  1,563.    Elapsed: 0:05:45.\n",
      "  Batch 1,450  of  1,563.    Elapsed: 0:05:58.\n",
      "  Batch 1,500  of  1,563.    Elapsed: 0:06:10.\n",
      "  Batch 1,550  of  1,563.    Elapsed: 0:06:23.\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 0:06:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation Loss: 0.38\n",
      "  Validation took: 0:01:43\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    50  of  1,563.    Elapsed: 0:00:12.\n",
      "  Batch   100  of  1,563.    Elapsed: 0:00:25.\n",
      "  Batch   150  of  1,563.    Elapsed: 0:00:37.\n",
      "  Batch   200  of  1,563.    Elapsed: 0:00:50.\n",
      "  Batch   250  of  1,563.    Elapsed: 0:01:02.\n",
      "  Batch   300  of  1,563.    Elapsed: 0:01:15.\n",
      "  Batch   350  of  1,563.    Elapsed: 0:01:27.\n",
      "  Batch   400  of  1,563.    Elapsed: 0:01:40.\n",
      "  Batch   450  of  1,563.    Elapsed: 0:01:52.\n",
      "  Batch   500  of  1,563.    Elapsed: 0:02:05.\n",
      "  Batch   550  of  1,563.    Elapsed: 0:02:17.\n",
      "  Batch   600  of  1,563.    Elapsed: 0:02:30.\n",
      "  Batch   650  of  1,563.    Elapsed: 0:02:42.\n",
      "  Batch   700  of  1,563.    Elapsed: 0:02:55.\n",
      "  Batch   750  of  1,563.    Elapsed: 0:03:07.\n",
      "  Batch   800  of  1,563.    Elapsed: 0:03:20.\n",
      "  Batch   850  of  1,563.    Elapsed: 0:03:32.\n",
      "  Batch   900  of  1,563.    Elapsed: 0:03:44.\n",
      "  Batch   950  of  1,563.    Elapsed: 0:03:57.\n",
      "  Batch 1,000  of  1,563.    Elapsed: 0:04:09.\n",
      "  Batch 1,050  of  1,563.    Elapsed: 0:04:22.\n",
      "  Batch 1,100  of  1,563.    Elapsed: 0:04:34.\n",
      "  Batch 1,150  of  1,563.    Elapsed: 0:04:47.\n",
      "  Batch 1,200  of  1,563.    Elapsed: 0:04:59.\n",
      "  Batch 1,250  of  1,563.    Elapsed: 0:05:12.\n",
      "  Batch 1,300  of  1,563.    Elapsed: 0:05:24.\n",
      "  Batch 1,350  of  1,563.    Elapsed: 0:05:37.\n",
      "  Batch 1,400  of  1,563.    Elapsed: 0:05:49.\n",
      "  Batch 1,450  of  1,563.    Elapsed: 0:06:02.\n",
      "  Batch 1,500  of  1,563.    Elapsed: 0:06:14.\n",
      "  Batch 1,550  of  1,563.    Elapsed: 0:06:27.\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:06:30\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83\n",
      "  Validation Loss: 0.41\n",
      "  Validation took: 0:01:43\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:16:21 (h:mm:ss)\n",
      "Predicting labels for 1,407 total test sentences...\n",
      "\n",
      "--- [전체 데이터셋] 테스트 결과 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.82      0.90      0.86     18987\n",
      " 비도덕성 있음 (1)       0.92      0.85      0.89     26011\n",
      "\n",
      "    accuracy                           0.87     44998\n",
      "   macro avg       0.87      0.88      0.87     44998\n",
      "weighted avg       0.88      0.87      0.87     44998\n",
      "\n",
      "    DONE (Total Test).\n",
      "\n",
      "\n",
      "--- [유형별 상세 테스트 결과] ---\n",
      "\n",
      "--- TEST 데이터를 모든 유형을 기준으로 분리 중... ---\n",
      "  - 유형: CENSURE              | 샘플 수: 19,866\n",
      "  - 유형: ABUSE                | 샘플 수: 1,474\n",
      "  - 유형: HATE                 | 샘플 수: 9,222\n",
      "  - 유형: VIOLENCE             | 샘플 수: 2,167\n",
      "  - 유형: CRIME                | 샘플 수: 1,075\n",
      "  - 유형: SEXUAL               | 샘플 수: 2,737\n",
      "  - 유형: DISCRIMINATION       | 샘플 수: 2,664\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: CENSURE ---\n",
      "총 샘플 수: 19,866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.87      0.93     19866\n",
      "\n",
      "    accuracy                           0.87     19866\n",
      "   macro avg       0.50      0.44      0.47     19866\n",
      "weighted avg       1.00      0.87      0.93     19866\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: ABUSE ---\n",
      "총 샘플 수: 1,474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.91      0.95      1474\n",
      "\n",
      "    accuracy                           0.91      1474\n",
      "   macro avg       0.50      0.46      0.48      1474\n",
      "weighted avg       1.00      0.91      0.95      1474\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: HATE ---\n",
      "총 샘플 수: 9,222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.91      0.95      9222\n",
      "\n",
      "    accuracy                           0.91      9222\n",
      "   macro avg       0.50      0.46      0.48      9222\n",
      "weighted avg       1.00      0.91      0.95      9222\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: VIOLENCE ---\n",
      "총 샘플 수: 2,167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.92      0.96      2167\n",
      "\n",
      "    accuracy                           0.92      2167\n",
      "   macro avg       0.50      0.46      0.48      2167\n",
      "weighted avg       1.00      0.92      0.96      2167\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: CRIME ---\n",
      "총 샘플 수: 1,075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.75      0.86      1075\n",
      "\n",
      "    accuracy                           0.75      1075\n",
      "   macro avg       0.50      0.38      0.43      1075\n",
      "weighted avg       1.00      0.75      0.86      1075\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: SEXUAL ---\n",
      "총 샘플 수: 2,737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.80      0.89      2737\n",
      "\n",
      "    accuracy                           0.80      2737\n",
      "   macro avg       0.50      0.40      0.45      2737\n",
      "weighted avg       1.00      0.80      0.89      2737\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: DISCRIMINATION ---\n",
      "총 샘플 수: 2,664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.88      0.93      2664\n",
      "\n",
      "    accuracy                           0.88      2664\n",
      "   macro avg       0.50      0.44      0.47      2664\n",
      "weighted avg       1.00      0.88      0.93      2664\n",
      "\n",
      "\n",
      "--- 유형별 상세 테스트 종료 ---\n",
      "Saving model to ./model_checkpoint\n",
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'ElectraTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./model_checkpoint\n",
      "'이런건 걍 돈없고 멍청한 전라도 여자들 겨냥한 상술이지' 은/는 폭력성이 포함된 문장입니다\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "\n",
    "from dataloader import Dataset\n",
    "from model import Models\n",
    "from transformers import BertTokenizer\n",
    "from utils import split_sentence\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def file_upload():\n",
    "    return render_template('load_file.html')\n",
    "    \n",
    "@app.route('/isViolence', methods = ['POST', 'GET'])\n",
    "def Predict():\n",
    "    if request.method == 'POST':\n",
    "        input_text = request.files['파일'].read().decode('utf-8') # 파일 불러오기\n",
    "        input_text = input_text.split('\\r\\n')\n",
    "        \n",
    "        if input_text == None:\n",
    "            return render_template('isViolence.html', Output = '')\n",
    "\n",
    "        sentences = split_sentence(input_text)  # 채팅 목록을 문장 단위로 분리\n",
    "        # print(sentences)\n",
    "        result = 0\n",
    "        for i, sentence in enumerate(sentences[:10000]):\n",
    "            if (i+1) % 1000 == 0:\n",
    "                print(f\"{i+1}번째 실행 중...\")\n",
    "            result += model.inference(sentence[-1])[1]\n",
    "        \n",
    "        ModelOutput = f\"해당 채팅방의 폭력성 대화 비율은 {round((result / len(sentences)) * 100, 2)}% 입니다\"\n",
    "        print(ModelOutput)\n",
    "        return render_template('isViolence.html', Output = ModelOutput)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    train_file_path = './data/train.csv'\n",
    "    valid_file_path = './data/val.csv'\n",
    "    test_file_path = './data/test.csv' \n",
    "    model_save_dir = './model_checkpoint'       # 모델 저장 디렉토리 경로\n",
    "    model_load_dir = './model_checkpoint'       # 모델 불러오기 디렉토리 경로\n",
    "\n",
    "    TRAIN_DATA_LIMIT = 50000\n",
    "\n",
    "    # # 1. 단일 Dataset 인스턴스 생성 및 데이터 로드\n",
    "    dataset = Dataset()\n",
    "    dataset.set_dataset('train', file_path=train_file_path, max_rows=TRAIN_DATA_LIMIT)\n",
    "    dataset.set_dataset('valid', file_path=valid_file_path)\n",
    "    dataset.set_dataset('test', file_path=test_file_path)\n",
    "\n",
    "    # # 2. Models 인스턴스 생성 및 Dataset 연결\n",
    "    # Models 인스턴스를 만들 때, dataset 객체를 인수로 전달합니다.\n",
    "    model = Models('koelectra', num_labels = 2, dataset_instance=dataset) \n",
    "    \n",
    "    # # 3. 모델 정의 및 토크나이저 설정\n",
    "    # model.BERT()를 호출하여 모델을 생성하고, 반환된 토크나이저를 dataset에 설정합니다.\n",
    "    tokenizer_for_training = model.BERT()  \n",
    "    dataset.set_tokenizer(tokenizer_for_training)\n",
    "    \n",
    "    print(dataset.get_tokenizer())\n",
    "    \n",
    "    # # 4. 데이터 로더 생성 (이제 올바른 토크나이저를 사용)\n",
    "    train, valid, test = dataset.get_dataloader()  \n",
    "    \n",
    "    model.about_model()\n",
    "    model.train(train, valid, epochs = 2, project_title=None) \n",
    "    model.test(test)\n",
    "    model.save_model(model_save_dir)\n",
    "\n",
    "    # # 5. 추론 및 웹 서버용 모델 로드 (새로운 인스턴스 생성 및 로드)\n",
    "    # 추론용 모델도 동일한 dataset 인스턴스를 사용하도록 연결\n",
    "    web_model = Models('koelectra', num_labels = 2, dataset_instance=dataset)\n",
    "    web_model.load_model(load_dir_path=model_load_dir)\n",
    "    \n",
    "    # # 6. 단일 문장 추론 테스트\n",
    "    sentence, prediction = web_model.inference('이런건 걍 돈없고 멍청한 전라도 여자들 겨냥한 상술이지')\n",
    "    print(f\"'{sentence}' 은/는 폭력성이 포함된 문장입니다\" if prediction == 1 else f\"'{sentence}' 은/는 폭력성이 포함되지 않은 문장입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5782aba-43aa-4272-8c58-770e8adf1f44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n",
      "max_length : 128\n",
      "[train]: 로드 중 파일: ./data/train.csv\n",
      "[train]: 총 1개의 파일에서 365,500개의 데이터를 성공적으로 병합했습니다.\n",
      "[train]: 원본 데이터 365,500개를 100,000개로 샘플링합니다.\n",
      "Train : 100000\n",
      "[valid]: 로드 중 파일: ./data/val.csv\n",
      "[valid]: 총 1개의 파일에서 40,612개의 데이터를 성공적으로 병합했습니다.\n",
      "Valid : 40612\n",
      "[test]: 로드 중 파일: ./data/test.csv\n",
      "[test]: 총 1개의 파일에서 44,998개의 데이터를 성공적으로 병합했습니다.\n",
      "Test : 44998\n",
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraTokenizer(name_or_path='monologg/koelectra-base-discriminator', vocab_size=32200, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n",
      "The KOELECTRA model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "electra.embeddings.word_embeddings.weight               (32200, 768)\n",
      "electra.embeddings.position_embeddings.weight             (512, 768)\n",
      "electra.embeddings.token_type_embeddings.weight             (2, 768)\n",
      "electra.embeddings.LayerNorm.weight                           (768,)\n",
      "electra.embeddings.LayerNorm.bias                             (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "electra.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
      "electra.encoder.layer.0.attention.self.query.bias             (768,)\n",
      "electra.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
      "electra.encoder.layer.0.attention.self.key.bias               (768,)\n",
      "electra.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
      "electra.encoder.layer.0.attention.self.value.bias             (768,)\n",
      "electra.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
      "electra.encoder.layer.0.attention.output.dense.bias           (768,)\n",
      "electra.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
      "electra.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
      "electra.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
      "electra.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
      "electra.encoder.layer.0.output.dense.weight              (768, 3072)\n",
      "electra.encoder.layer.0.output.dense.bias                     (768,)\n",
      "electra.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
      "electra.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "classifier.dense.weight                                   (768, 768)\n",
      "classifier.dense.bias                                         (768,)\n",
      "classifier.out_proj.weight                                  (2, 768)\n",
      "classifier.out_proj.bias                                        (2,)\n",
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    50  of  3,125.    Elapsed: 0:00:12.\n",
      "  Batch   100  of  3,125.    Elapsed: 0:00:24.\n",
      "  Batch   150  of  3,125.    Elapsed: 0:00:36.\n",
      "  Batch   200  of  3,125.    Elapsed: 0:00:48.\n",
      "  Batch   250  of  3,125.    Elapsed: 0:01:01.\n",
      "  Batch   300  of  3,125.    Elapsed: 0:01:13.\n",
      "  Batch   350  of  3,125.    Elapsed: 0:01:25.\n",
      "  Batch   400  of  3,125.    Elapsed: 0:01:38.\n",
      "  Batch   450  of  3,125.    Elapsed: 0:01:50.\n",
      "  Batch   500  of  3,125.    Elapsed: 0:02:02.\n",
      "  Batch   550  of  3,125.    Elapsed: 0:02:15.\n",
      "  Batch   600  of  3,125.    Elapsed: 0:02:27.\n",
      "  Batch   650  of  3,125.    Elapsed: 0:02:40.\n",
      "  Batch   700  of  3,125.    Elapsed: 0:02:52.\n",
      "  Batch   750  of  3,125.    Elapsed: 0:03:05.\n",
      "  Batch   800  of  3,125.    Elapsed: 0:03:17.\n",
      "  Batch   850  of  3,125.    Elapsed: 0:03:29.\n",
      "  Batch   900  of  3,125.    Elapsed: 0:03:42.\n",
      "  Batch   950  of  3,125.    Elapsed: 0:03:54.\n",
      "  Batch 1,000  of  3,125.    Elapsed: 0:04:07.\n",
      "  Batch 1,050  of  3,125.    Elapsed: 0:04:19.\n",
      "  Batch 1,100  of  3,125.    Elapsed: 0:04:32.\n",
      "  Batch 1,150  of  3,125.    Elapsed: 0:04:44.\n",
      "  Batch 1,200  of  3,125.    Elapsed: 0:04:57.\n",
      "  Batch 1,250  of  3,125.    Elapsed: 0:05:09.\n",
      "  Batch 1,300  of  3,125.    Elapsed: 0:05:22.\n",
      "  Batch 1,350  of  3,125.    Elapsed: 0:05:34.\n",
      "  Batch 1,400  of  3,125.    Elapsed: 0:05:47.\n",
      "  Batch 1,450  of  3,125.    Elapsed: 0:05:59.\n",
      "  Batch 1,500  of  3,125.    Elapsed: 0:06:12.\n",
      "  Batch 1,550  of  3,125.    Elapsed: 0:06:24.\n",
      "  Batch 1,600  of  3,125.    Elapsed: 0:06:36.\n",
      "  Batch 1,650  of  3,125.    Elapsed: 0:06:49.\n",
      "  Batch 1,700  of  3,125.    Elapsed: 0:07:01.\n",
      "  Batch 1,750  of  3,125.    Elapsed: 0:07:14.\n",
      "  Batch 1,800  of  3,125.    Elapsed: 0:07:26.\n",
      "  Batch 1,850  of  3,125.    Elapsed: 0:07:39.\n",
      "  Batch 1,900  of  3,125.    Elapsed: 0:07:51.\n",
      "  Batch 1,950  of  3,125.    Elapsed: 0:08:04.\n",
      "  Batch 2,000  of  3,125.    Elapsed: 0:08:16.\n",
      "  Batch 2,050  of  3,125.    Elapsed: 0:08:29.\n",
      "  Batch 2,100  of  3,125.    Elapsed: 0:08:41.\n",
      "  Batch 2,150  of  3,125.    Elapsed: 0:08:54.\n",
      "  Batch 2,200  of  3,125.    Elapsed: 0:09:06.\n",
      "  Batch 2,250  of  3,125.    Elapsed: 0:09:18.\n",
      "  Batch 2,300  of  3,125.    Elapsed: 0:09:31.\n",
      "  Batch 2,350  of  3,125.    Elapsed: 0:09:43.\n",
      "  Batch 2,400  of  3,125.    Elapsed: 0:09:56.\n",
      "  Batch 2,450  of  3,125.    Elapsed: 0:10:08.\n",
      "  Batch 2,500  of  3,125.    Elapsed: 0:10:21.\n",
      "  Batch 2,550  of  3,125.    Elapsed: 0:10:33.\n",
      "  Batch 2,600  of  3,125.    Elapsed: 0:10:46.\n",
      "  Batch 2,650  of  3,125.    Elapsed: 0:10:58.\n",
      "  Batch 2,700  of  3,125.    Elapsed: 0:11:10.\n",
      "  Batch 2,750  of  3,125.    Elapsed: 0:11:23.\n",
      "  Batch 2,800  of  3,125.    Elapsed: 0:11:35.\n",
      "  Batch 2,850  of  3,125.    Elapsed: 0:11:48.\n",
      "  Batch 2,900  of  3,125.    Elapsed: 0:12:00.\n",
      "  Batch 2,950  of  3,125.    Elapsed: 0:12:13.\n",
      "  Batch 3,000  of  3,125.    Elapsed: 0:12:25.\n",
      "  Batch 3,050  of  3,125.    Elapsed: 0:12:37.\n",
      "  Batch 3,100  of  3,125.    Elapsed: 0:12:50.\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:12:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation Loss: 0.38\n",
      "  Validation took: 0:01:43\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    50  of  3,125.    Elapsed: 0:00:12.\n",
      "  Batch   100  of  3,125.    Elapsed: 0:00:25.\n",
      "  Batch   150  of  3,125.    Elapsed: 0:00:37.\n",
      "  Batch   200  of  3,125.    Elapsed: 0:00:50.\n",
      "  Batch   250  of  3,125.    Elapsed: 0:01:02.\n",
      "  Batch   300  of  3,125.    Elapsed: 0:01:14.\n",
      "  Batch   350  of  3,125.    Elapsed: 0:01:27.\n",
      "  Batch   400  of  3,125.    Elapsed: 0:01:39.\n",
      "  Batch   450  of  3,125.    Elapsed: 0:01:52.\n",
      "  Batch   500  of  3,125.    Elapsed: 0:02:04.\n",
      "  Batch   550  of  3,125.    Elapsed: 0:02:16.\n",
      "  Batch   600  of  3,125.    Elapsed: 0:02:29.\n",
      "  Batch   650  of  3,125.    Elapsed: 0:02:41.\n",
      "  Batch   700  of  3,125.    Elapsed: 0:02:54.\n",
      "  Batch   750  of  3,125.    Elapsed: 0:03:06.\n",
      "  Batch   800  of  3,125.    Elapsed: 0:03:19.\n",
      "  Batch   850  of  3,125.    Elapsed: 0:03:31.\n",
      "  Batch   900  of  3,125.    Elapsed: 0:03:43.\n",
      "  Batch   950  of  3,125.    Elapsed: 0:03:56.\n",
      "  Batch 1,000  of  3,125.    Elapsed: 0:04:08.\n",
      "  Batch 1,050  of  3,125.    Elapsed: 0:04:21.\n",
      "  Batch 1,100  of  3,125.    Elapsed: 0:04:33.\n",
      "  Batch 1,150  of  3,125.    Elapsed: 0:04:45.\n",
      "  Batch 1,200  of  3,125.    Elapsed: 0:04:58.\n",
      "  Batch 1,250  of  3,125.    Elapsed: 0:05:10.\n",
      "  Batch 1,300  of  3,125.    Elapsed: 0:05:23.\n",
      "  Batch 1,350  of  3,125.    Elapsed: 0:05:35.\n",
      "  Batch 1,400  of  3,125.    Elapsed: 0:05:47.\n",
      "  Batch 1,450  of  3,125.    Elapsed: 0:06:00.\n",
      "  Batch 1,500  of  3,125.    Elapsed: 0:06:12.\n",
      "  Batch 1,550  of  3,125.    Elapsed: 0:06:25.\n",
      "  Batch 1,600  of  3,125.    Elapsed: 0:06:37.\n",
      "  Batch 1,650  of  3,125.    Elapsed: 0:06:49.\n",
      "  Batch 1,700  of  3,125.    Elapsed: 0:07:02.\n",
      "  Batch 1,750  of  3,125.    Elapsed: 0:07:14.\n",
      "  Batch 1,800  of  3,125.    Elapsed: 0:07:27.\n",
      "  Batch 1,850  of  3,125.    Elapsed: 0:07:39.\n",
      "  Batch 1,900  of  3,125.    Elapsed: 0:07:51.\n",
      "  Batch 1,950  of  3,125.    Elapsed: 0:08:04.\n",
      "  Batch 2,000  of  3,125.    Elapsed: 0:08:16.\n",
      "  Batch 2,050  of  3,125.    Elapsed: 0:08:29.\n",
      "  Batch 2,100  of  3,125.    Elapsed: 0:08:41.\n",
      "  Batch 2,150  of  3,125.    Elapsed: 0:08:54.\n",
      "  Batch 2,200  of  3,125.    Elapsed: 0:09:06.\n",
      "  Batch 2,250  of  3,125.    Elapsed: 0:09:18.\n",
      "  Batch 2,300  of  3,125.    Elapsed: 0:09:31.\n",
      "  Batch 2,350  of  3,125.    Elapsed: 0:09:43.\n",
      "  Batch 2,400  of  3,125.    Elapsed: 0:09:56.\n",
      "  Batch 2,450  of  3,125.    Elapsed: 0:10:08.\n",
      "  Batch 2,500  of  3,125.    Elapsed: 0:10:20.\n",
      "  Batch 2,550  of  3,125.    Elapsed: 0:10:33.\n",
      "  Batch 2,600  of  3,125.    Elapsed: 0:10:45.\n",
      "  Batch 2,650  of  3,125.    Elapsed: 0:10:58.\n",
      "  Batch 2,700  of  3,125.    Elapsed: 0:11:10.\n",
      "  Batch 2,750  of  3,125.    Elapsed: 0:11:23.\n",
      "  Batch 2,800  of  3,125.    Elapsed: 0:11:35.\n",
      "  Batch 2,850  of  3,125.    Elapsed: 0:11:47.\n",
      "  Batch 2,900  of  3,125.    Elapsed: 0:12:00.\n",
      "  Batch 2,950  of  3,125.    Elapsed: 0:12:12.\n",
      "  Batch 3,000  of  3,125.    Elapsed: 0:12:25.\n",
      "  Batch 3,050  of  3,125.    Elapsed: 0:12:37.\n",
      "  Batch 3,100  of  3,125.    Elapsed: 0:12:50.\n",
      "\n",
      "  Average training loss: 0.31\n",
      "  Training epcoh took: 0:12:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation Loss: 0.38\n",
      "  Validation took: 0:01:43\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:29:18 (h:mm:ss)\n",
      "Predicting labels for 1,407 total test sentences...\n",
      "\n",
      "--- [전체 데이터셋] 테스트 결과 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.85      0.89      0.87     18987\n",
      " 비도덕성 있음 (1)       0.92      0.88      0.90     26011\n",
      "\n",
      "    accuracy                           0.88     44998\n",
      "   macro avg       0.88      0.88      0.88     44998\n",
      "weighted avg       0.89      0.88      0.88     44998\n",
      "\n",
      "    DONE (Total Test).\n",
      "\n",
      "\n",
      "--- [유형별 상세 테스트 결과] ---\n",
      "\n",
      "--- TEST 데이터를 모든 유형을 기준으로 분리 중... ---\n",
      "  - 유형: CENSURE              | 샘플 수: 19,866\n",
      "  - 유형: ABUSE                | 샘플 수: 1,474\n",
      "  - 유형: HATE                 | 샘플 수: 9,222\n",
      "  - 유형: VIOLENCE             | 샘플 수: 2,167\n",
      "  - 유형: CRIME                | 샘플 수: 1,075\n",
      "  - 유형: SEXUAL               | 샘플 수: 2,737\n",
      "  - 유형: DISCRIMINATION       | 샘플 수: 2,664\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: CENSURE ---\n",
      "총 샘플 수: 19,866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.89      0.94     19866\n",
      "\n",
      "    accuracy                           0.89     19866\n",
      "   macro avg       0.50      0.45      0.47     19866\n",
      "weighted avg       1.00      0.89      0.94     19866\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: ABUSE ---\n",
      "총 샘플 수: 1,474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.94      0.97      1474\n",
      "\n",
      "    accuracy                           0.94      1474\n",
      "   macro avg       0.50      0.47      0.48      1474\n",
      "weighted avg       1.00      0.94      0.97      1474\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: HATE ---\n",
      "총 샘플 수: 9,222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.93      0.96      9222\n",
      "\n",
      "    accuracy                           0.93      9222\n",
      "   macro avg       0.50      0.47      0.48      9222\n",
      "weighted avg       1.00      0.93      0.96      9222\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: VIOLENCE ---\n",
      "총 샘플 수: 2,167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.94      0.97      2167\n",
      "\n",
      "    accuracy                           0.94      2167\n",
      "   macro avg       0.50      0.47      0.49      2167\n",
      "weighted avg       1.00      0.94      0.97      2167\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: CRIME ---\n",
      "총 샘플 수: 1,075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.80      0.89      1075\n",
      "\n",
      "    accuracy                           0.80      1075\n",
      "   macro avg       0.50      0.40      0.44      1075\n",
      "weighted avg       1.00      0.80      0.89      1075\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: SEXUAL ---\n",
      "총 샘플 수: 2,737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.84      0.91      2737\n",
      "\n",
      "    accuracy                           0.84      2737\n",
      "   macro avg       0.50      0.42      0.46      2737\n",
      "weighted avg       1.00      0.84      0.91      2737\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: DISCRIMINATION ---\n",
      "총 샘플 수: 2,664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.91      0.95      2664\n",
      "\n",
      "    accuracy                           0.91      2664\n",
      "   macro avg       0.50      0.45      0.48      2664\n",
      "weighted avg       1.00      0.91      0.95      2664\n",
      "\n",
      "\n",
      "--- 유형별 상세 테스트 종료 ---\n",
      "Saving model to ./model_checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -lcufile\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'ElectraTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./model_checkpoint\n",
      "'이런건 걍 돈없고 멍청한 전라도 여자들 겨냥한 상술이지' 은/는 폭력성이 포함된 문장입니다\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "\n",
    "from dataloader import Dataset\n",
    "from model import Models\n",
    "from transformers import BertTokenizer\n",
    "from utils import split_sentence\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def file_upload():\n",
    "    return render_template('load_file.html')\n",
    "    \n",
    "@app.route('/isViolence', methods = ['POST', 'GET'])\n",
    "def Predict():\n",
    "    if request.method == 'POST':\n",
    "        input_text = request.files['파일'].read().decode('utf-8') # 파일 불러오기\n",
    "        input_text = input_text.split('\\r\\n')\n",
    "        \n",
    "        if input_text == None:\n",
    "            return render_template('isViolence.html', Output = '')\n",
    "\n",
    "        sentences = split_sentence(input_text)  # 채팅 목록을 문장 단위로 분리\n",
    "        # print(sentences)\n",
    "        result = 0\n",
    "        for i, sentence in enumerate(sentences[:10000]):\n",
    "            if (i+1) % 1000 == 0:\n",
    "                print(f\"{i+1}번째 실행 중...\")\n",
    "            result += model.inference(sentence[-1])[1]\n",
    "        \n",
    "        ModelOutput = f\"해당 채팅방의 폭력성 대화 비율은 {round((result / len(sentences)) * 100, 2)}% 입니다\"\n",
    "        print(ModelOutput)\n",
    "        return render_template('isViolence.html', Output = ModelOutput)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    train_file_path = './data/train.csv'\n",
    "    valid_file_path = './data/val.csv'\n",
    "    test_file_path = './data/test.csv' \n",
    "    model_save_dir = './model_checkpoint'       # 모델 저장 디렉토리 경로\n",
    "    model_load_dir = './model_checkpoint'       # 모델 불러오기 디렉토리 경로\n",
    "\n",
    "    TRAIN_DATA_LIMIT = 100000\n",
    "\n",
    "    # # 1. 단일 Dataset 인스턴스 생성 및 데이터 로드\n",
    "    dataset = Dataset()\n",
    "    dataset.set_dataset('train', file_path=train_file_path, max_rows=TRAIN_DATA_LIMIT)\n",
    "    dataset.set_dataset('valid', file_path=valid_file_path)\n",
    "    dataset.set_dataset('test', file_path=test_file_path)\n",
    "\n",
    "    # # 2. Models 인스턴스 생성 및 Dataset 연결\n",
    "    # Models 인스턴스를 만들 때, dataset 객체를 인수로 전달합니다.\n",
    "    model = Models('koelectra', num_labels = 2, dataset_instance=dataset) \n",
    "    \n",
    "    # # 3. 모델 정의 및 토크나이저 설정\n",
    "    # model.BERT()를 호출하여 모델을 생성하고, 반환된 토크나이저를 dataset에 설정합니다.\n",
    "    tokenizer_for_training = model.BERT()  \n",
    "    dataset.set_tokenizer(tokenizer_for_training)\n",
    "    \n",
    "    print(dataset.get_tokenizer())\n",
    "    \n",
    "    # # 4. 데이터 로더 생성 (이제 올바른 토크나이저를 사용)\n",
    "    train, valid, test = dataset.get_dataloader()  \n",
    "    \n",
    "    model.about_model()\n",
    "    model.train(train, valid, epochs = 2, project_title=None) \n",
    "    model.test(test)\n",
    "    model.save_model(model_save_dir)\n",
    "\n",
    "    # # 5. 추론 및 웹 서버용 모델 로드 (새로운 인스턴스 생성 및 로드)\n",
    "    # 추론용 모델도 동일한 dataset 인스턴스를 사용하도록 연결\n",
    "    web_model = Models('koelectra', num_labels = 2, dataset_instance=dataset)\n",
    "    web_model.load_model(load_dir_path=model_load_dir)\n",
    "    \n",
    "    # # 6. 단일 문장 추론 테스트\n",
    "    sentence, prediction = web_model.inference('이런건 걍 돈없고 멍청한 전라도 여자들 겨냥한 상술이지')\n",
    "    print(f\"'{sentence}' 은/는 폭력성이 포함된 문장입니다\" if prediction == 1 else f\"'{sentence}' 은/는 폭력성이 포함되지 않은 문장입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b68474b2-425e-4786-8907-40ab3ab08470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n",
      "max_length : 128\n",
      "[train]: 로드 중 파일: ./data/train.csv\n",
      "[train]: 총 1개의 파일에서 365,500개의 데이터를 성공적으로 병합했습니다.\n",
      "[train]: 원본 데이터 365,500개를 200,000개로 샘플링합니다.\n",
      "Train : 200000\n",
      "[valid]: 로드 중 파일: ./data/val.csv\n",
      "[valid]: 총 1개의 파일에서 40,612개의 데이터를 성공적으로 병합했습니다.\n",
      "Valid : 40612\n",
      "[test]: 로드 중 파일: ./data/test.csv\n",
      "[test]: 총 1개의 파일에서 44,998개의 데이터를 성공적으로 병합했습니다.\n",
      "Test : 44998\n",
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraTokenizer(name_or_path='monologg/koelectra-base-discriminator', vocab_size=32200, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n",
      "The KOELECTRA model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "electra.embeddings.word_embeddings.weight               (32200, 768)\n",
      "electra.embeddings.position_embeddings.weight             (512, 768)\n",
      "electra.embeddings.token_type_embeddings.weight             (2, 768)\n",
      "electra.embeddings.LayerNorm.weight                           (768,)\n",
      "electra.embeddings.LayerNorm.bias                             (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "electra.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
      "electra.encoder.layer.0.attention.self.query.bias             (768,)\n",
      "electra.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
      "electra.encoder.layer.0.attention.self.key.bias               (768,)\n",
      "electra.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
      "electra.encoder.layer.0.attention.self.value.bias             (768,)\n",
      "electra.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
      "electra.encoder.layer.0.attention.output.dense.bias           (768,)\n",
      "electra.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
      "electra.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
      "electra.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
      "electra.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
      "electra.encoder.layer.0.output.dense.weight              (768, 3072)\n",
      "electra.encoder.layer.0.output.dense.bias                     (768,)\n",
      "electra.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
      "electra.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "classifier.dense.weight                                   (768, 768)\n",
      "classifier.dense.bias                                         (768,)\n",
      "classifier.out_proj.weight                                  (2, 768)\n",
      "classifier.out_proj.bias                                        (2,)\n",
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    50  of  6,250.    Elapsed: 0:00:12.\n",
      "  Batch   100  of  6,250.    Elapsed: 0:00:24.\n",
      "  Batch   150  of  6,250.    Elapsed: 0:00:36.\n",
      "  Batch   200  of  6,250.    Elapsed: 0:00:48.\n",
      "  Batch   250  of  6,250.    Elapsed: 0:01:00.\n",
      "  Batch   300  of  6,250.    Elapsed: 0:01:12.\n",
      "  Batch   350  of  6,250.    Elapsed: 0:01:25.\n",
      "  Batch   400  of  6,250.    Elapsed: 0:01:37.\n",
      "  Batch   450  of  6,250.    Elapsed: 0:01:49.\n",
      "  Batch   500  of  6,250.    Elapsed: 0:02:02.\n",
      "  Batch   550  of  6,250.    Elapsed: 0:02:14.\n",
      "  Batch   600  of  6,250.    Elapsed: 0:02:27.\n",
      "  Batch   650  of  6,250.    Elapsed: 0:02:39.\n",
      "  Batch   700  of  6,250.    Elapsed: 0:02:51.\n",
      "  Batch   750  of  6,250.    Elapsed: 0:03:04.\n",
      "  Batch   800  of  6,250.    Elapsed: 0:03:16.\n",
      "  Batch   850  of  6,250.    Elapsed: 0:03:29.\n",
      "  Batch   900  of  6,250.    Elapsed: 0:03:41.\n",
      "  Batch   950  of  6,250.    Elapsed: 0:03:54.\n",
      "  Batch 1,000  of  6,250.    Elapsed: 0:04:06.\n",
      "  Batch 1,050  of  6,250.    Elapsed: 0:04:18.\n",
      "  Batch 1,100  of  6,250.    Elapsed: 0:04:31.\n",
      "  Batch 1,150  of  6,250.    Elapsed: 0:04:43.\n",
      "  Batch 1,200  of  6,250.    Elapsed: 0:04:56.\n",
      "  Batch 1,250  of  6,250.    Elapsed: 0:05:08.\n",
      "  Batch 1,300  of  6,250.    Elapsed: 0:05:21.\n",
      "  Batch 1,350  of  6,250.    Elapsed: 0:05:33.\n",
      "  Batch 1,400  of  6,250.    Elapsed: 0:05:46.\n",
      "  Batch 1,450  of  6,250.    Elapsed: 0:05:58.\n",
      "  Batch 1,500  of  6,250.    Elapsed: 0:06:11.\n",
      "  Batch 1,550  of  6,250.    Elapsed: 0:06:23.\n",
      "  Batch 1,600  of  6,250.    Elapsed: 0:06:35.\n",
      "  Batch 1,650  of  6,250.    Elapsed: 0:06:48.\n",
      "  Batch 1,700  of  6,250.    Elapsed: 0:07:00.\n",
      "  Batch 1,750  of  6,250.    Elapsed: 0:07:13.\n",
      "  Batch 1,800  of  6,250.    Elapsed: 0:07:25.\n",
      "  Batch 1,850  of  6,250.    Elapsed: 0:07:38.\n",
      "  Batch 1,900  of  6,250.    Elapsed: 0:07:50.\n",
      "  Batch 1,950  of  6,250.    Elapsed: 0:08:03.\n",
      "  Batch 2,000  of  6,250.    Elapsed: 0:08:15.\n",
      "  Batch 2,050  of  6,250.    Elapsed: 0:08:28.\n",
      "  Batch 2,100  of  6,250.    Elapsed: 0:08:40.\n",
      "  Batch 2,150  of  6,250.    Elapsed: 0:08:53.\n",
      "  Batch 2,200  of  6,250.    Elapsed: 0:09:05.\n",
      "  Batch 2,250  of  6,250.    Elapsed: 0:09:18.\n",
      "  Batch 2,300  of  6,250.    Elapsed: 0:09:30.\n",
      "  Batch 2,350  of  6,250.    Elapsed: 0:09:42.\n",
      "  Batch 2,400  of  6,250.    Elapsed: 0:09:55.\n",
      "  Batch 2,450  of  6,250.    Elapsed: 0:10:07.\n",
      "  Batch 2,500  of  6,250.    Elapsed: 0:10:20.\n",
      "  Batch 2,550  of  6,250.    Elapsed: 0:10:32.\n",
      "  Batch 2,600  of  6,250.    Elapsed: 0:10:45.\n",
      "  Batch 2,650  of  6,250.    Elapsed: 0:10:57.\n",
      "  Batch 2,700  of  6,250.    Elapsed: 0:11:10.\n",
      "  Batch 2,750  of  6,250.    Elapsed: 0:11:22.\n",
      "  Batch 2,800  of  6,250.    Elapsed: 0:11:35.\n",
      "  Batch 2,850  of  6,250.    Elapsed: 0:11:47.\n",
      "  Batch 2,900  of  6,250.    Elapsed: 0:11:59.\n",
      "  Batch 2,950  of  6,250.    Elapsed: 0:12:12.\n",
      "  Batch 3,000  of  6,250.    Elapsed: 0:12:24.\n",
      "  Batch 3,050  of  6,250.    Elapsed: 0:12:37.\n",
      "  Batch 3,100  of  6,250.    Elapsed: 0:12:49.\n",
      "  Batch 3,150  of  6,250.    Elapsed: 0:13:02.\n",
      "  Batch 3,200  of  6,250.    Elapsed: 0:13:14.\n",
      "  Batch 3,250  of  6,250.    Elapsed: 0:13:26.\n",
      "  Batch 3,300  of  6,250.    Elapsed: 0:13:39.\n",
      "  Batch 3,350  of  6,250.    Elapsed: 0:13:51.\n",
      "  Batch 3,400  of  6,250.    Elapsed: 0:14:04.\n",
      "  Batch 3,450  of  6,250.    Elapsed: 0:14:16.\n",
      "  Batch 3,500  of  6,250.    Elapsed: 0:14:29.\n",
      "  Batch 3,550  of  6,250.    Elapsed: 0:14:41.\n",
      "  Batch 3,600  of  6,250.    Elapsed: 0:14:53.\n",
      "  Batch 3,650  of  6,250.    Elapsed: 0:15:06.\n",
      "  Batch 3,700  of  6,250.    Elapsed: 0:15:18.\n",
      "  Batch 3,750  of  6,250.    Elapsed: 0:15:31.\n",
      "  Batch 3,800  of  6,250.    Elapsed: 0:15:43.\n",
      "  Batch 3,850  of  6,250.    Elapsed: 0:15:56.\n",
      "  Batch 3,900  of  6,250.    Elapsed: 0:16:08.\n",
      "  Batch 3,950  of  6,250.    Elapsed: 0:16:20.\n",
      "  Batch 4,000  of  6,250.    Elapsed: 0:16:33.\n",
      "  Batch 4,050  of  6,250.    Elapsed: 0:16:45.\n",
      "  Batch 4,100  of  6,250.    Elapsed: 0:16:58.\n",
      "  Batch 4,150  of  6,250.    Elapsed: 0:17:10.\n",
      "  Batch 4,200  of  6,250.    Elapsed: 0:17:22.\n",
      "  Batch 4,250  of  6,250.    Elapsed: 0:17:35.\n",
      "  Batch 4,300  of  6,250.    Elapsed: 0:17:47.\n",
      "  Batch 4,350  of  6,250.    Elapsed: 0:18:00.\n",
      "  Batch 4,400  of  6,250.    Elapsed: 0:18:12.\n",
      "  Batch 4,450  of  6,250.    Elapsed: 0:18:24.\n",
      "  Batch 4,500  of  6,250.    Elapsed: 0:18:37.\n",
      "  Batch 4,550  of  6,250.    Elapsed: 0:18:49.\n",
      "  Batch 4,600  of  6,250.    Elapsed: 0:19:02.\n",
      "  Batch 4,650  of  6,250.    Elapsed: 0:19:14.\n",
      "  Batch 4,700  of  6,250.    Elapsed: 0:19:27.\n",
      "  Batch 4,750  of  6,250.    Elapsed: 0:19:39.\n",
      "  Batch 4,800  of  6,250.    Elapsed: 0:19:51.\n",
      "  Batch 4,850  of  6,250.    Elapsed: 0:20:04.\n",
      "  Batch 4,900  of  6,250.    Elapsed: 0:20:16.\n",
      "  Batch 4,950  of  6,250.    Elapsed: 0:20:29.\n",
      "  Batch 5,000  of  6,250.    Elapsed: 0:20:41.\n",
      "  Batch 5,050  of  6,250.    Elapsed: 0:20:54.\n",
      "  Batch 5,100  of  6,250.    Elapsed: 0:21:06.\n",
      "  Batch 5,150  of  6,250.    Elapsed: 0:21:18.\n",
      "  Batch 5,200  of  6,250.    Elapsed: 0:21:31.\n",
      "  Batch 5,250  of  6,250.    Elapsed: 0:21:43.\n",
      "  Batch 5,300  of  6,250.    Elapsed: 0:21:56.\n",
      "  Batch 5,350  of  6,250.    Elapsed: 0:22:08.\n",
      "  Batch 5,400  of  6,250.    Elapsed: 0:22:21.\n",
      "  Batch 5,450  of  6,250.    Elapsed: 0:22:33.\n",
      "  Batch 5,500  of  6,250.    Elapsed: 0:22:45.\n",
      "  Batch 5,550  of  6,250.    Elapsed: 0:22:58.\n",
      "  Batch 5,600  of  6,250.    Elapsed: 0:23:10.\n",
      "  Batch 5,650  of  6,250.    Elapsed: 0:23:23.\n",
      "  Batch 5,700  of  6,250.    Elapsed: 0:23:35.\n",
      "  Batch 5,750  of  6,250.    Elapsed: 0:23:48.\n",
      "  Batch 5,800  of  6,250.    Elapsed: 0:24:00.\n",
      "  Batch 5,850  of  6,250.    Elapsed: 0:24:13.\n",
      "  Batch 5,900  of  6,250.    Elapsed: 0:24:25.\n",
      "  Batch 5,950  of  6,250.    Elapsed: 0:24:38.\n",
      "  Batch 6,000  of  6,250.    Elapsed: 0:24:50.\n",
      "  Batch 6,050  of  6,250.    Elapsed: 0:25:02.\n",
      "  Batch 6,100  of  6,250.    Elapsed: 0:25:15.\n",
      "  Batch 6,150  of  6,250.    Elapsed: 0:25:27.\n",
      "  Batch 6,200  of  6,250.    Elapsed: 0:25:40.\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:25:52\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation Loss: 0.36\n",
      "  Validation took: 0:01:43\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    50  of  6,250.    Elapsed: 0:00:12.\n",
      "  Batch   100  of  6,250.    Elapsed: 0:00:25.\n",
      "  Batch   150  of  6,250.    Elapsed: 0:00:37.\n",
      "  Batch   200  of  6,250.    Elapsed: 0:00:50.\n",
      "  Batch   250  of  6,250.    Elapsed: 0:01:02.\n",
      "  Batch   300  of  6,250.    Elapsed: 0:01:15.\n",
      "  Batch   350  of  6,250.    Elapsed: 0:01:27.\n",
      "  Batch   400  of  6,250.    Elapsed: 0:01:39.\n",
      "  Batch   450  of  6,250.    Elapsed: 0:01:52.\n",
      "  Batch   500  of  6,250.    Elapsed: 0:02:04.\n",
      "  Batch   550  of  6,250.    Elapsed: 0:02:17.\n",
      "  Batch   600  of  6,250.    Elapsed: 0:02:29.\n",
      "  Batch   650  of  6,250.    Elapsed: 0:02:42.\n",
      "  Batch   700  of  6,250.    Elapsed: 0:02:54.\n",
      "  Batch   750  of  6,250.    Elapsed: 0:03:06.\n",
      "  Batch   800  of  6,250.    Elapsed: 0:03:19.\n",
      "  Batch   850  of  6,250.    Elapsed: 0:03:31.\n",
      "  Batch   900  of  6,250.    Elapsed: 0:03:44.\n",
      "  Batch   950  of  6,250.    Elapsed: 0:03:56.\n",
      "  Batch 1,000  of  6,250.    Elapsed: 0:04:08.\n",
      "  Batch 1,050  of  6,250.    Elapsed: 0:04:21.\n",
      "  Batch 1,100  of  6,250.    Elapsed: 0:04:33.\n",
      "  Batch 1,150  of  6,250.    Elapsed: 0:04:46.\n",
      "  Batch 1,200  of  6,250.    Elapsed: 0:04:58.\n",
      "  Batch 1,250  of  6,250.    Elapsed: 0:05:10.\n",
      "  Batch 1,300  of  6,250.    Elapsed: 0:05:23.\n",
      "  Batch 1,350  of  6,250.    Elapsed: 0:05:35.\n",
      "  Batch 1,400  of  6,250.    Elapsed: 0:05:48.\n",
      "  Batch 1,450  of  6,250.    Elapsed: 0:06:00.\n",
      "  Batch 1,500  of  6,250.    Elapsed: 0:06:13.\n",
      "  Batch 1,550  of  6,250.    Elapsed: 0:06:25.\n",
      "  Batch 1,600  of  6,250.    Elapsed: 0:06:37.\n",
      "  Batch 1,650  of  6,250.    Elapsed: 0:06:50.\n",
      "  Batch 1,700  of  6,250.    Elapsed: 0:07:02.\n",
      "  Batch 1,750  of  6,250.    Elapsed: 0:07:15.\n",
      "  Batch 1,800  of  6,250.    Elapsed: 0:07:27.\n",
      "  Batch 1,850  of  6,250.    Elapsed: 0:07:39.\n",
      "  Batch 1,900  of  6,250.    Elapsed: 0:07:52.\n",
      "  Batch 1,950  of  6,250.    Elapsed: 0:08:04.\n",
      "  Batch 2,000  of  6,250.    Elapsed: 0:08:17.\n",
      "  Batch 2,050  of  6,250.    Elapsed: 0:08:29.\n",
      "  Batch 2,100  of  6,250.    Elapsed: 0:08:41.\n",
      "  Batch 2,150  of  6,250.    Elapsed: 0:08:54.\n",
      "  Batch 2,200  of  6,250.    Elapsed: 0:09:06.\n",
      "  Batch 2,250  of  6,250.    Elapsed: 0:09:19.\n",
      "  Batch 2,300  of  6,250.    Elapsed: 0:09:31.\n",
      "  Batch 2,350  of  6,250.    Elapsed: 0:09:44.\n",
      "  Batch 2,400  of  6,250.    Elapsed: 0:09:56.\n",
      "  Batch 2,450  of  6,250.    Elapsed: 0:10:08.\n",
      "  Batch 2,500  of  6,250.    Elapsed: 0:10:21.\n",
      "  Batch 2,550  of  6,250.    Elapsed: 0:10:33.\n",
      "  Batch 2,600  of  6,250.    Elapsed: 0:10:46.\n",
      "  Batch 2,650  of  6,250.    Elapsed: 0:10:58.\n",
      "  Batch 2,700  of  6,250.    Elapsed: 0:11:11.\n",
      "  Batch 2,750  of  6,250.    Elapsed: 0:11:23.\n",
      "  Batch 2,800  of  6,250.    Elapsed: 0:11:35.\n",
      "  Batch 2,850  of  6,250.    Elapsed: 0:11:48.\n",
      "  Batch 2,900  of  6,250.    Elapsed: 0:12:00.\n",
      "  Batch 2,950  of  6,250.    Elapsed: 0:12:13.\n",
      "  Batch 3,000  of  6,250.    Elapsed: 0:12:25.\n",
      "  Batch 3,050  of  6,250.    Elapsed: 0:12:38.\n",
      "  Batch 3,100  of  6,250.    Elapsed: 0:12:50.\n",
      "  Batch 3,150  of  6,250.    Elapsed: 0:13:02.\n",
      "  Batch 3,200  of  6,250.    Elapsed: 0:13:15.\n",
      "  Batch 3,250  of  6,250.    Elapsed: 0:13:27.\n",
      "  Batch 3,300  of  6,250.    Elapsed: 0:13:40.\n",
      "  Batch 3,350  of  6,250.    Elapsed: 0:13:52.\n",
      "  Batch 3,400  of  6,250.    Elapsed: 0:14:05.\n",
      "  Batch 3,450  of  6,250.    Elapsed: 0:14:17.\n",
      "  Batch 3,500  of  6,250.    Elapsed: 0:14:29.\n",
      "  Batch 3,550  of  6,250.    Elapsed: 0:14:42.\n",
      "  Batch 3,600  of  6,250.    Elapsed: 0:14:54.\n",
      "  Batch 3,650  of  6,250.    Elapsed: 0:15:07.\n",
      "  Batch 3,700  of  6,250.    Elapsed: 0:15:19.\n",
      "  Batch 3,750  of  6,250.    Elapsed: 0:15:32.\n",
      "  Batch 3,800  of  6,250.    Elapsed: 0:15:44.\n",
      "  Batch 3,850  of  6,250.    Elapsed: 0:15:57.\n",
      "  Batch 3,900  of  6,250.    Elapsed: 0:16:09.\n",
      "  Batch 3,950  of  6,250.    Elapsed: 0:16:21.\n",
      "  Batch 4,000  of  6,250.    Elapsed: 0:16:34.\n",
      "  Batch 4,050  of  6,250.    Elapsed: 0:16:46.\n",
      "  Batch 4,100  of  6,250.    Elapsed: 0:16:59.\n",
      "  Batch 4,150  of  6,250.    Elapsed: 0:17:11.\n",
      "  Batch 4,200  of  6,250.    Elapsed: 0:17:24.\n",
      "  Batch 4,250  of  6,250.    Elapsed: 0:17:36.\n",
      "  Batch 4,300  of  6,250.    Elapsed: 0:17:49.\n",
      "  Batch 4,350  of  6,250.    Elapsed: 0:18:01.\n",
      "  Batch 4,400  of  6,250.    Elapsed: 0:18:13.\n",
      "  Batch 4,450  of  6,250.    Elapsed: 0:18:26.\n",
      "  Batch 4,500  of  6,250.    Elapsed: 0:18:38.\n",
      "  Batch 4,550  of  6,250.    Elapsed: 0:18:51.\n",
      "  Batch 4,600  of  6,250.    Elapsed: 0:19:03.\n",
      "  Batch 4,650  of  6,250.    Elapsed: 0:19:16.\n",
      "  Batch 4,700  of  6,250.    Elapsed: 0:19:28.\n",
      "  Batch 4,750  of  6,250.    Elapsed: 0:19:40.\n",
      "  Batch 4,800  of  6,250.    Elapsed: 0:19:53.\n",
      "  Batch 4,850  of  6,250.    Elapsed: 0:20:05.\n",
      "  Batch 4,900  of  6,250.    Elapsed: 0:20:18.\n",
      "  Batch 4,950  of  6,250.    Elapsed: 0:20:30.\n",
      "  Batch 5,000  of  6,250.    Elapsed: 0:20:42.\n",
      "  Batch 5,050  of  6,250.    Elapsed: 0:20:55.\n",
      "  Batch 5,100  of  6,250.    Elapsed: 0:21:07.\n",
      "  Batch 5,150  of  6,250.    Elapsed: 0:21:20.\n",
      "  Batch 5,200  of  6,250.    Elapsed: 0:21:32.\n",
      "  Batch 5,250  of  6,250.    Elapsed: 0:21:45.\n",
      "  Batch 5,300  of  6,250.    Elapsed: 0:21:57.\n",
      "  Batch 5,350  of  6,250.    Elapsed: 0:22:09.\n",
      "  Batch 5,400  of  6,250.    Elapsed: 0:22:22.\n",
      "  Batch 5,450  of  6,250.    Elapsed: 0:22:34.\n",
      "  Batch 5,500  of  6,250.    Elapsed: 0:22:47.\n",
      "  Batch 5,550  of  6,250.    Elapsed: 0:22:59.\n",
      "  Batch 5,600  of  6,250.    Elapsed: 0:23:11.\n",
      "  Batch 5,650  of  6,250.    Elapsed: 0:23:24.\n",
      "  Batch 5,700  of  6,250.    Elapsed: 0:23:36.\n",
      "  Batch 5,750  of  6,250.    Elapsed: 0:23:49.\n",
      "  Batch 5,800  of  6,250.    Elapsed: 0:24:01.\n",
      "  Batch 5,850  of  6,250.    Elapsed: 0:24:14.\n",
      "  Batch 5,900  of  6,250.    Elapsed: 0:24:26.\n",
      "  Batch 5,950  of  6,250.    Elapsed: 0:24:38.\n",
      "  Batch 6,000  of  6,250.    Elapsed: 0:24:51.\n",
      "  Batch 6,050  of  6,250.    Elapsed: 0:25:03.\n",
      "  Batch 6,100  of  6,250.    Elapsed: 0:25:16.\n",
      "  Batch 6,150  of  6,250.    Elapsed: 0:25:28.\n",
      "  Batch 6,200  of  6,250.    Elapsed: 0:25:40.\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:25:53\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation Loss: 0.38\n",
      "  Validation took: 0:01:43\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:55:11 (h:mm:ss)\n",
      "Predicting labels for 1,407 total test sentences...\n",
      "\n",
      "--- [전체 데이터셋] 테스트 결과 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.85      0.91      0.88     18987\n",
      " 비도덕성 있음 (1)       0.93      0.88      0.90     26011\n",
      "\n",
      "    accuracy                           0.89     44998\n",
      "   macro avg       0.89      0.89      0.89     44998\n",
      "weighted avg       0.89      0.89      0.89     44998\n",
      "\n",
      "    DONE (Total Test).\n",
      "\n",
      "\n",
      "--- [유형별 상세 테스트 결과] ---\n",
      "\n",
      "--- TEST 데이터를 모든 유형을 기준으로 분리 중... ---\n",
      "  - 유형: CENSURE              | 샘플 수: 19,866\n",
      "  - 유형: ABUSE                | 샘플 수: 1,474\n",
      "  - 유형: HATE                 | 샘플 수: 9,222\n",
      "  - 유형: VIOLENCE             | 샘플 수: 2,167\n",
      "  - 유형: CRIME                | 샘플 수: 1,075\n",
      "  - 유형: SEXUAL               | 샘플 수: 2,737\n",
      "  - 유형: DISCRIMINATION       | 샘플 수: 2,664\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: CENSURE ---\n",
      "총 샘플 수: 19,866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.89      0.94     19866\n",
      "\n",
      "    accuracy                           0.89     19866\n",
      "   macro avg       0.50      0.45      0.47     19866\n",
      "weighted avg       1.00      0.89      0.94     19866\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: ABUSE ---\n",
      "총 샘플 수: 1,474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.95      0.97      1474\n",
      "\n",
      "    accuracy                           0.95      1474\n",
      "   macro avg       0.50      0.47      0.49      1474\n",
      "weighted avg       1.00      0.95      0.97      1474\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: HATE ---\n",
      "총 샘플 수: 9,222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.93      0.96      9222\n",
      "\n",
      "    accuracy                           0.93      9222\n",
      "   macro avg       0.50      0.46      0.48      9222\n",
      "weighted avg       1.00      0.93      0.96      9222\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: VIOLENCE ---\n",
      "총 샘플 수: 2,167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.94      0.97      2167\n",
      "\n",
      "    accuracy                           0.94      2167\n",
      "   macro avg       0.50      0.47      0.48      2167\n",
      "weighted avg       1.00      0.94      0.97      2167\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: CRIME ---\n",
      "총 샘플 수: 1,075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.79      0.88      1075\n",
      "\n",
      "    accuracy                           0.79      1075\n",
      "   macro avg       0.50      0.39      0.44      1075\n",
      "weighted avg       1.00      0.79      0.88      1075\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: SEXUAL ---\n",
      "총 샘플 수: 2,737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.84      0.91      2737\n",
      "\n",
      "    accuracy                           0.84      2737\n",
      "   macro avg       0.50      0.42      0.46      2737\n",
      "weighted avg       1.00      0.84      0.91      2737\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: DISCRIMINATION ---\n",
      "총 샘플 수: 2,664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.90      0.95      2664\n",
      "\n",
      "    accuracy                           0.90      2664\n",
      "   macro avg       0.50      0.45      0.47      2664\n",
      "weighted avg       1.00      0.90      0.95      2664\n",
      "\n",
      "\n",
      "--- 유형별 상세 테스트 종료 ---\n",
      "Saving model to ./model_checkpoint\n",
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'ElectraTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./model_checkpoint\n",
      "'이런건 걍 돈없고 멍청한 전라도 여자들 겨냥한 상술이지' 은/는 폭력성이 포함된 문장입니다\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "\n",
    "from dataloader import Dataset\n",
    "from model import Models\n",
    "from transformers import BertTokenizer\n",
    "from utils import split_sentence\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def file_upload():\n",
    "    return render_template('load_file.html')\n",
    "    \n",
    "@app.route('/isViolence', methods = ['POST', 'GET'])\n",
    "def Predict():\n",
    "    if request.method == 'POST':\n",
    "        input_text = request.files['파일'].read().decode('utf-8') # 파일 불러오기\n",
    "        input_text = input_text.split('\\r\\n')\n",
    "        \n",
    "        if input_text == None:\n",
    "            return render_template('isViolence.html', Output = '')\n",
    "\n",
    "        sentences = split_sentence(input_text)  # 채팅 목록을 문장 단위로 분리\n",
    "        # print(sentences)\n",
    "        result = 0\n",
    "        for i, sentence in enumerate(sentences[:10000]):\n",
    "            if (i+1) % 1000 == 0:\n",
    "                print(f\"{i+1}번째 실행 중...\")\n",
    "            result += model.inference(sentence[-1])[1]\n",
    "        \n",
    "        ModelOutput = f\"해당 채팅방의 폭력성 대화 비율은 {round((result / len(sentences)) * 100, 2)}% 입니다\"\n",
    "        print(ModelOutput)\n",
    "        return render_template('isViolence.html', Output = ModelOutput)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    train_file_path = './data/train.csv'\n",
    "    valid_file_path = './data/val.csv'\n",
    "    test_file_path = './data/test.csv' \n",
    "    model_save_dir = './model_checkpoint'       # 모델 저장 디렉토리 경로\n",
    "    model_load_dir = './model_checkpoint'       # 모델 불러오기 디렉토리 경로\n",
    "\n",
    "    TRAIN_DATA_LIMIT = 200000\n",
    "\n",
    "    # # 1. 단일 Dataset 인스턴스 생성 및 데이터 로드\n",
    "    dataset = Dataset()\n",
    "    dataset.set_dataset('train', file_path=train_file_path, max_rows=TRAIN_DATA_LIMIT)\n",
    "    dataset.set_dataset('valid', file_path=valid_file_path)\n",
    "    dataset.set_dataset('test', file_path=test_file_path)\n",
    "\n",
    "    # # 2. Models 인스턴스 생성 및 Dataset 연결\n",
    "    # Models 인스턴스를 만들 때, dataset 객체를 인수로 전달합니다.\n",
    "    model = Models('koelectra', num_labels = 2, dataset_instance=dataset) \n",
    "    \n",
    "    # # 3. 모델 정의 및 토크나이저 설정\n",
    "    # model.BERT()를 호출하여 모델을 생성하고, 반환된 토크나이저를 dataset에 설정합니다.\n",
    "    tokenizer_for_training = model.BERT()  \n",
    "    dataset.set_tokenizer(tokenizer_for_training)\n",
    "    \n",
    "    print(dataset.get_tokenizer())\n",
    "    \n",
    "    # # 4. 데이터 로더 생성 (이제 올바른 토크나이저를 사용)\n",
    "    train, valid, test = dataset.get_dataloader()  \n",
    "    \n",
    "    model.about_model()\n",
    "    model.train(train, valid, epochs = 2, project_title=None) \n",
    "    model.test(test)\n",
    "    model.save_model(model_save_dir)\n",
    "\n",
    "    # # 5. 추론 및 웹 서버용 모델 로드 (새로운 인스턴스 생성 및 로드)\n",
    "    # 추론용 모델도 동일한 dataset 인스턴스를 사용하도록 연결\n",
    "    web_model = Models('koelectra', num_labels = 2, dataset_instance=dataset)\n",
    "    web_model.load_model(load_dir_path=model_load_dir)\n",
    "    \n",
    "    # # 6. 단일 문장 추론 테스트\n",
    "    sentence, prediction = web_model.inference('이런건 걍 돈없고 멍청한 전라도 여자들 겨냥한 상술이지')\n",
    "    print(f\"'{sentence}' 은/는 폭력성이 포함된 문장입니다\" if prediction == 1 else f\"'{sentence}' 은/는 폭력성이 포함되지 않은 문장입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19121076-be6e-489c-b45a-e20ea847ec86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n",
      "max_length : 128\n",
      "[train]: 로드 중 파일: ./data/train.csv\n",
      "[train]: 총 1개의 파일에서 365,500개의 데이터를 성공적으로 병합했습니다.\n",
      "Train : 365500\n",
      "[valid]: 로드 중 파일: ./data/val.csv\n",
      "[valid]: 총 1개의 파일에서 40,612개의 데이터를 성공적으로 병합했습니다.\n",
      "Valid : 40612\n",
      "[test]: 로드 중 파일: ./data/test.csv\n",
      "[test]: 총 1개의 파일에서 44,998개의 데이터를 성공적으로 병합했습니다.\n",
      "Test : 44998\n",
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraTokenizer(name_or_path='monologg/koelectra-base-discriminator', vocab_size=32200, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n",
      "The KOELECTRA model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "electra.embeddings.word_embeddings.weight               (32200, 768)\n",
      "electra.embeddings.position_embeddings.weight             (512, 768)\n",
      "electra.embeddings.token_type_embeddings.weight             (2, 768)\n",
      "electra.embeddings.LayerNorm.weight                           (768,)\n",
      "electra.embeddings.LayerNorm.bias                             (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "electra.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
      "electra.encoder.layer.0.attention.self.query.bias             (768,)\n",
      "electra.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
      "electra.encoder.layer.0.attention.self.key.bias               (768,)\n",
      "electra.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
      "electra.encoder.layer.0.attention.self.value.bias             (768,)\n",
      "electra.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
      "electra.encoder.layer.0.attention.output.dense.bias           (768,)\n",
      "electra.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
      "electra.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
      "electra.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
      "electra.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
      "electra.encoder.layer.0.output.dense.weight              (768, 3072)\n",
      "electra.encoder.layer.0.output.dense.bias                     (768,)\n",
      "electra.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
      "electra.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "classifier.dense.weight                                   (768, 768)\n",
      "classifier.dense.bias                                         (768,)\n",
      "classifier.out_proj.weight                                  (2, 768)\n",
      "classifier.out_proj.bias                                        (2,)\n",
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    50  of  11,422.    Elapsed: 0:00:12.\n",
      "  Batch   100  of  11,422.    Elapsed: 0:00:23.\n",
      "  Batch   150  of  11,422.    Elapsed: 0:00:35.\n",
      "  Batch   200  of  11,422.    Elapsed: 0:00:47.\n",
      "  Batch   250  of  11,422.    Elapsed: 0:01:00.\n",
      "  Batch   300  of  11,422.    Elapsed: 0:01:12.\n",
      "  Batch   350  of  11,422.    Elapsed: 0:01:24.\n",
      "  Batch   400  of  11,422.    Elapsed: 0:01:36.\n",
      "  Batch   450  of  11,422.    Elapsed: 0:01:49.\n",
      "  Batch   500  of  11,422.    Elapsed: 0:02:01.\n",
      "  Batch   550  of  11,422.    Elapsed: 0:02:13.\n",
      "  Batch   600  of  11,422.    Elapsed: 0:02:26.\n",
      "  Batch   650  of  11,422.    Elapsed: 0:02:38.\n",
      "  Batch   700  of  11,422.    Elapsed: 0:02:50.\n",
      "  Batch   750  of  11,422.    Elapsed: 0:03:03.\n",
      "  Batch   800  of  11,422.    Elapsed: 0:03:15.\n",
      "  Batch   850  of  11,422.    Elapsed: 0:03:28.\n",
      "  Batch   900  of  11,422.    Elapsed: 0:03:40.\n",
      "  Batch   950  of  11,422.    Elapsed: 0:03:52.\n",
      "  Batch 1,000  of  11,422.    Elapsed: 0:04:05.\n",
      "  Batch 1,050  of  11,422.    Elapsed: 0:04:17.\n",
      "  Batch 1,100  of  11,422.    Elapsed: 0:04:30.\n",
      "  Batch 1,150  of  11,422.    Elapsed: 0:04:42.\n",
      "  Batch 1,200  of  11,422.    Elapsed: 0:04:55.\n",
      "  Batch 1,250  of  11,422.    Elapsed: 0:05:07.\n",
      "  Batch 1,300  of  11,422.    Elapsed: 0:05:19.\n",
      "  Batch 1,350  of  11,422.    Elapsed: 0:05:32.\n",
      "  Batch 1,400  of  11,422.    Elapsed: 0:05:44.\n",
      "  Batch 1,450  of  11,422.    Elapsed: 0:05:57.\n",
      "  Batch 1,500  of  11,422.    Elapsed: 0:06:09.\n",
      "  Batch 1,550  of  11,422.    Elapsed: 0:06:21.\n",
      "  Batch 1,600  of  11,422.    Elapsed: 0:06:34.\n",
      "  Batch 1,650  of  11,422.    Elapsed: 0:06:46.\n",
      "  Batch 1,700  of  11,422.    Elapsed: 0:06:59.\n",
      "  Batch 1,750  of  11,422.    Elapsed: 0:07:11.\n",
      "  Batch 1,800  of  11,422.    Elapsed: 0:07:24.\n",
      "  Batch 1,850  of  11,422.    Elapsed: 0:07:36.\n",
      "  Batch 1,900  of  11,422.    Elapsed: 0:07:48.\n",
      "  Batch 1,950  of  11,422.    Elapsed: 0:08:01.\n",
      "  Batch 2,000  of  11,422.    Elapsed: 0:08:13.\n",
      "  Batch 2,050  of  11,422.    Elapsed: 0:08:26.\n",
      "  Batch 2,100  of  11,422.    Elapsed: 0:08:38.\n",
      "  Batch 2,150  of  11,422.    Elapsed: 0:08:51.\n",
      "  Batch 2,200  of  11,422.    Elapsed: 0:09:03.\n",
      "  Batch 2,250  of  11,422.    Elapsed: 0:09:15.\n",
      "  Batch 2,300  of  11,422.    Elapsed: 0:09:28.\n",
      "  Batch 2,350  of  11,422.    Elapsed: 0:09:40.\n",
      "  Batch 2,400  of  11,422.    Elapsed: 0:09:53.\n",
      "  Batch 2,450  of  11,422.    Elapsed: 0:10:05.\n",
      "  Batch 2,500  of  11,422.    Elapsed: 0:10:17.\n",
      "  Batch 2,550  of  11,422.    Elapsed: 0:10:30.\n",
      "  Batch 2,600  of  11,422.    Elapsed: 0:10:42.\n",
      "  Batch 2,650  of  11,422.    Elapsed: 0:10:55.\n",
      "  Batch 2,700  of  11,422.    Elapsed: 0:11:07.\n",
      "  Batch 2,750  of  11,422.    Elapsed: 0:11:20.\n",
      "  Batch 2,800  of  11,422.    Elapsed: 0:11:32.\n",
      "  Batch 2,850  of  11,422.    Elapsed: 0:11:45.\n",
      "  Batch 2,900  of  11,422.    Elapsed: 0:11:57.\n",
      "  Batch 2,950  of  11,422.    Elapsed: 0:12:09.\n",
      "  Batch 3,000  of  11,422.    Elapsed: 0:12:22.\n",
      "  Batch 3,050  of  11,422.    Elapsed: 0:12:34.\n",
      "  Batch 3,100  of  11,422.    Elapsed: 0:12:47.\n",
      "  Batch 3,150  of  11,422.    Elapsed: 0:12:59.\n",
      "  Batch 3,200  of  11,422.    Elapsed: 0:13:12.\n",
      "  Batch 3,250  of  11,422.    Elapsed: 0:13:24.\n",
      "  Batch 3,300  of  11,422.    Elapsed: 0:13:36.\n",
      "  Batch 3,350  of  11,422.    Elapsed: 0:13:49.\n",
      "  Batch 3,400  of  11,422.    Elapsed: 0:14:01.\n",
      "  Batch 3,450  of  11,422.    Elapsed: 0:14:14.\n",
      "  Batch 3,500  of  11,422.    Elapsed: 0:14:26.\n",
      "  Batch 3,550  of  11,422.    Elapsed: 0:14:39.\n",
      "  Batch 3,600  of  11,422.    Elapsed: 0:14:51.\n",
      "  Batch 3,650  of  11,422.    Elapsed: 0:15:04.\n",
      "  Batch 3,700  of  11,422.    Elapsed: 0:15:16.\n",
      "  Batch 3,750  of  11,422.    Elapsed: 0:15:29.\n",
      "  Batch 3,800  of  11,422.    Elapsed: 0:15:41.\n",
      "  Batch 3,850  of  11,422.    Elapsed: 0:15:53.\n",
      "  Batch 3,900  of  11,422.    Elapsed: 0:16:06.\n",
      "  Batch 3,950  of  11,422.    Elapsed: 0:16:18.\n",
      "  Batch 4,000  of  11,422.    Elapsed: 0:16:31.\n",
      "  Batch 4,050  of  11,422.    Elapsed: 0:16:43.\n",
      "  Batch 4,100  of  11,422.    Elapsed: 0:16:56.\n",
      "  Batch 4,150  of  11,422.    Elapsed: 0:17:08.\n",
      "  Batch 4,200  of  11,422.    Elapsed: 0:17:21.\n",
      "  Batch 4,250  of  11,422.    Elapsed: 0:17:33.\n",
      "  Batch 4,300  of  11,422.    Elapsed: 0:17:46.\n",
      "  Batch 4,350  of  11,422.    Elapsed: 0:17:58.\n",
      "  Batch 4,400  of  11,422.    Elapsed: 0:18:11.\n",
      "  Batch 4,450  of  11,422.    Elapsed: 0:18:23.\n",
      "  Batch 4,500  of  11,422.    Elapsed: 0:18:36.\n",
      "  Batch 4,550  of  11,422.    Elapsed: 0:18:48.\n",
      "  Batch 4,600  of  11,422.    Elapsed: 0:19:00.\n",
      "  Batch 4,650  of  11,422.    Elapsed: 0:19:13.\n",
      "  Batch 4,700  of  11,422.    Elapsed: 0:19:25.\n",
      "  Batch 4,750  of  11,422.    Elapsed: 0:19:38.\n",
      "  Batch 4,800  of  11,422.    Elapsed: 0:19:50.\n",
      "  Batch 4,850  of  11,422.    Elapsed: 0:20:03.\n",
      "  Batch 4,900  of  11,422.    Elapsed: 0:20:15.\n",
      "  Batch 4,950  of  11,422.    Elapsed: 0:20:28.\n",
      "  Batch 5,000  of  11,422.    Elapsed: 0:20:40.\n",
      "  Batch 5,050  of  11,422.    Elapsed: 0:20:53.\n",
      "  Batch 5,100  of  11,422.    Elapsed: 0:21:05.\n",
      "  Batch 5,150  of  11,422.    Elapsed: 0:21:18.\n",
      "  Batch 5,200  of  11,422.    Elapsed: 0:21:30.\n",
      "  Batch 5,250  of  11,422.    Elapsed: 0:21:43.\n",
      "  Batch 5,300  of  11,422.    Elapsed: 0:21:55.\n",
      "  Batch 5,350  of  11,422.    Elapsed: 0:22:07.\n",
      "  Batch 5,400  of  11,422.    Elapsed: 0:22:20.\n",
      "  Batch 5,450  of  11,422.    Elapsed: 0:22:32.\n",
      "  Batch 5,500  of  11,422.    Elapsed: 0:22:45.\n",
      "  Batch 5,550  of  11,422.    Elapsed: 0:22:57.\n",
      "  Batch 5,600  of  11,422.    Elapsed: 0:23:10.\n",
      "  Batch 5,650  of  11,422.    Elapsed: 0:23:22.\n",
      "  Batch 5,700  of  11,422.    Elapsed: 0:23:35.\n",
      "  Batch 5,750  of  11,422.    Elapsed: 0:23:47.\n",
      "  Batch 5,800  of  11,422.    Elapsed: 0:24:00.\n",
      "  Batch 5,850  of  11,422.    Elapsed: 0:24:12.\n",
      "  Batch 5,900  of  11,422.    Elapsed: 0:24:25.\n",
      "  Batch 5,950  of  11,422.    Elapsed: 0:24:37.\n",
      "  Batch 6,000  of  11,422.    Elapsed: 0:24:49.\n",
      "  Batch 6,050  of  11,422.    Elapsed: 0:25:02.\n",
      "  Batch 6,100  of  11,422.    Elapsed: 0:25:14.\n",
      "  Batch 6,150  of  11,422.    Elapsed: 0:25:27.\n",
      "  Batch 6,200  of  11,422.    Elapsed: 0:25:39.\n",
      "  Batch 6,250  of  11,422.    Elapsed: 0:25:52.\n",
      "  Batch 6,300  of  11,422.    Elapsed: 0:26:04.\n",
      "  Batch 6,350  of  11,422.    Elapsed: 0:26:17.\n",
      "  Batch 6,400  of  11,422.    Elapsed: 0:26:29.\n",
      "  Batch 6,450  of  11,422.    Elapsed: 0:26:42.\n",
      "  Batch 6,500  of  11,422.    Elapsed: 0:26:54.\n",
      "  Batch 6,550  of  11,422.    Elapsed: 0:27:07.\n",
      "  Batch 6,600  of  11,422.    Elapsed: 0:27:19.\n",
      "  Batch 6,650  of  11,422.    Elapsed: 0:27:31.\n",
      "  Batch 6,700  of  11,422.    Elapsed: 0:27:44.\n",
      "  Batch 6,750  of  11,422.    Elapsed: 0:27:56.\n",
      "  Batch 6,800  of  11,422.    Elapsed: 0:28:09.\n",
      "  Batch 6,850  of  11,422.    Elapsed: 0:28:21.\n",
      "  Batch 6,900  of  11,422.    Elapsed: 0:28:34.\n",
      "  Batch 6,950  of  11,422.    Elapsed: 0:28:46.\n",
      "  Batch 7,000  of  11,422.    Elapsed: 0:28:59.\n",
      "  Batch 7,050  of  11,422.    Elapsed: 0:29:11.\n",
      "  Batch 7,100  of  11,422.    Elapsed: 0:29:24.\n",
      "  Batch 7,150  of  11,422.    Elapsed: 0:29:36.\n",
      "  Batch 7,200  of  11,422.    Elapsed: 0:29:49.\n",
      "  Batch 7,250  of  11,422.    Elapsed: 0:30:01.\n",
      "  Batch 7,300  of  11,422.    Elapsed: 0:30:13.\n",
      "  Batch 7,350  of  11,422.    Elapsed: 0:30:26.\n",
      "  Batch 7,400  of  11,422.    Elapsed: 0:30:38.\n",
      "  Batch 7,450  of  11,422.    Elapsed: 0:30:51.\n",
      "  Batch 7,500  of  11,422.    Elapsed: 0:31:03.\n",
      "  Batch 7,550  of  11,422.    Elapsed: 0:31:16.\n",
      "  Batch 7,600  of  11,422.    Elapsed: 0:31:28.\n",
      "  Batch 7,650  of  11,422.    Elapsed: 0:31:41.\n",
      "  Batch 7,700  of  11,422.    Elapsed: 0:31:53.\n",
      "  Batch 7,750  of  11,422.    Elapsed: 0:32:05.\n",
      "  Batch 7,800  of  11,422.    Elapsed: 0:32:18.\n",
      "  Batch 7,850  of  11,422.    Elapsed: 0:32:30.\n",
      "  Batch 7,900  of  11,422.    Elapsed: 0:32:43.\n",
      "  Batch 7,950  of  11,422.    Elapsed: 0:32:55.\n",
      "  Batch 8,000  of  11,422.    Elapsed: 0:33:08.\n",
      "  Batch 8,050  of  11,422.    Elapsed: 0:33:20.\n",
      "  Batch 8,100  of  11,422.    Elapsed: 0:33:33.\n",
      "  Batch 8,150  of  11,422.    Elapsed: 0:33:45.\n",
      "  Batch 8,200  of  11,422.    Elapsed: 0:33:57.\n",
      "  Batch 8,250  of  11,422.    Elapsed: 0:34:10.\n",
      "  Batch 8,300  of  11,422.    Elapsed: 0:34:22.\n",
      "  Batch 8,350  of  11,422.    Elapsed: 0:34:35.\n",
      "  Batch 8,400  of  11,422.    Elapsed: 0:34:47.\n",
      "  Batch 8,450  of  11,422.    Elapsed: 0:35:00.\n",
      "  Batch 8,500  of  11,422.    Elapsed: 0:35:12.\n",
      "  Batch 8,550  of  11,422.    Elapsed: 0:35:25.\n",
      "  Batch 8,600  of  11,422.    Elapsed: 0:35:37.\n",
      "  Batch 8,650  of  11,422.    Elapsed: 0:35:50.\n",
      "  Batch 8,700  of  11,422.    Elapsed: 0:36:02.\n",
      "  Batch 8,750  of  11,422.    Elapsed: 0:36:15.\n",
      "  Batch 8,800  of  11,422.    Elapsed: 0:36:27.\n",
      "  Batch 8,850  of  11,422.    Elapsed: 0:36:40.\n",
      "  Batch 8,900  of  11,422.    Elapsed: 0:36:52.\n",
      "  Batch 8,950  of  11,422.    Elapsed: 0:37:04.\n",
      "  Batch 9,000  of  11,422.    Elapsed: 0:37:17.\n",
      "  Batch 9,050  of  11,422.    Elapsed: 0:37:29.\n",
      "  Batch 9,100  of  11,422.    Elapsed: 0:37:42.\n",
      "  Batch 9,150  of  11,422.    Elapsed: 0:37:54.\n",
      "  Batch 9,200  of  11,422.    Elapsed: 0:38:07.\n",
      "  Batch 9,250  of  11,422.    Elapsed: 0:38:19.\n",
      "  Batch 9,300  of  11,422.    Elapsed: 0:38:32.\n",
      "  Batch 9,350  of  11,422.    Elapsed: 0:38:44.\n",
      "  Batch 9,400  of  11,422.    Elapsed: 0:38:57.\n",
      "  Batch 9,450  of  11,422.    Elapsed: 0:39:09.\n",
      "  Batch 9,500  of  11,422.    Elapsed: 0:39:22.\n",
      "  Batch 9,550  of  11,422.    Elapsed: 0:39:34.\n",
      "  Batch 9,600  of  11,422.    Elapsed: 0:39:47.\n",
      "  Batch 9,650  of  11,422.    Elapsed: 0:39:59.\n",
      "  Batch 9,700  of  11,422.    Elapsed: 0:40:11.\n",
      "  Batch 9,750  of  11,422.    Elapsed: 0:40:24.\n",
      "  Batch 9,800  of  11,422.    Elapsed: 0:40:36.\n",
      "  Batch 9,850  of  11,422.    Elapsed: 0:40:49.\n",
      "  Batch 9,900  of  11,422.    Elapsed: 0:41:01.\n",
      "  Batch 9,950  of  11,422.    Elapsed: 0:41:14.\n",
      "  Batch 10,000  of  11,422.    Elapsed: 0:41:26.\n",
      "  Batch 10,050  of  11,422.    Elapsed: 0:41:39.\n",
      "  Batch 10,100  of  11,422.    Elapsed: 0:41:51.\n",
      "  Batch 10,150  of  11,422.    Elapsed: 0:42:04.\n",
      "  Batch 10,200  of  11,422.    Elapsed: 0:42:16.\n",
      "  Batch 10,250  of  11,422.    Elapsed: 0:42:29.\n",
      "  Batch 10,300  of  11,422.    Elapsed: 0:42:41.\n",
      "  Batch 10,350  of  11,422.    Elapsed: 0:42:54.\n",
      "  Batch 10,400  of  11,422.    Elapsed: 0:43:06.\n",
      "  Batch 10,450  of  11,422.    Elapsed: 0:43:18.\n",
      "  Batch 10,500  of  11,422.    Elapsed: 0:43:31.\n",
      "  Batch 10,550  of  11,422.    Elapsed: 0:43:43.\n",
      "  Batch 10,600  of  11,422.    Elapsed: 0:43:56.\n",
      "  Batch 10,650  of  11,422.    Elapsed: 0:44:08.\n",
      "  Batch 10,700  of  11,422.    Elapsed: 0:44:21.\n",
      "  Batch 10,750  of  11,422.    Elapsed: 0:44:33.\n",
      "  Batch 10,800  of  11,422.    Elapsed: 0:44:46.\n",
      "  Batch 10,850  of  11,422.    Elapsed: 0:44:58.\n",
      "  Batch 10,900  of  11,422.    Elapsed: 0:45:11.\n",
      "  Batch 10,950  of  11,422.    Elapsed: 0:45:23.\n",
      "  Batch 11,000  of  11,422.    Elapsed: 0:45:35.\n",
      "  Batch 11,050  of  11,422.    Elapsed: 0:45:48.\n",
      "  Batch 11,100  of  11,422.    Elapsed: 0:46:00.\n",
      "  Batch 11,150  of  11,422.    Elapsed: 0:46:13.\n",
      "  Batch 11,200  of  11,422.    Elapsed: 0:46:25.\n",
      "  Batch 11,250  of  11,422.    Elapsed: 0:46:38.\n",
      "  Batch 11,300  of  11,422.    Elapsed: 0:46:50.\n",
      "  Batch 11,350  of  11,422.    Elapsed: 0:47:02.\n",
      "  Batch 11,400  of  11,422.    Elapsed: 0:47:15.\n",
      "\n",
      "  Average training loss: 0.37\n",
      "  Training epcoh took: 0:47:20\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation Loss: 0.34\n",
      "  Validation took: 0:01:43\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    50  of  11,422.    Elapsed: 0:00:12.\n",
      "  Batch   100  of  11,422.    Elapsed: 0:00:25.\n",
      "  Batch   150  of  11,422.    Elapsed: 0:00:37.\n",
      "  Batch   200  of  11,422.    Elapsed: 0:00:50.\n",
      "  Batch   250  of  11,422.    Elapsed: 0:01:02.\n",
      "  Batch   300  of  11,422.    Elapsed: 0:01:15.\n",
      "  Batch   350  of  11,422.    Elapsed: 0:01:27.\n",
      "  Batch   400  of  11,422.    Elapsed: 0:01:39.\n",
      "  Batch   450  of  11,422.    Elapsed: 0:01:52.\n",
      "  Batch   500  of  11,422.    Elapsed: 0:02:04.\n",
      "  Batch   550  of  11,422.    Elapsed: 0:02:17.\n",
      "  Batch   600  of  11,422.    Elapsed: 0:02:29.\n",
      "  Batch   650  of  11,422.    Elapsed: 0:02:42.\n",
      "  Batch   700  of  11,422.    Elapsed: 0:02:54.\n",
      "  Batch   750  of  11,422.    Elapsed: 0:03:07.\n",
      "  Batch   800  of  11,422.    Elapsed: 0:03:19.\n",
      "  Batch   850  of  11,422.    Elapsed: 0:03:32.\n",
      "  Batch   900  of  11,422.    Elapsed: 0:03:44.\n",
      "  Batch   950  of  11,422.    Elapsed: 0:03:56.\n",
      "  Batch 1,000  of  11,422.    Elapsed: 0:04:09.\n",
      "  Batch 1,050  of  11,422.    Elapsed: 0:04:21.\n",
      "  Batch 1,100  of  11,422.    Elapsed: 0:04:34.\n",
      "  Batch 1,150  of  11,422.    Elapsed: 0:04:46.\n",
      "  Batch 1,200  of  11,422.    Elapsed: 0:04:59.\n",
      "  Batch 1,250  of  11,422.    Elapsed: 0:05:11.\n",
      "  Batch 1,300  of  11,422.    Elapsed: 0:05:24.\n",
      "  Batch 1,350  of  11,422.    Elapsed: 0:05:36.\n",
      "  Batch 1,400  of  11,422.    Elapsed: 0:05:49.\n",
      "  Batch 1,450  of  11,422.    Elapsed: 0:06:01.\n",
      "  Batch 1,500  of  11,422.    Elapsed: 0:06:14.\n",
      "  Batch 1,550  of  11,422.    Elapsed: 0:06:26.\n",
      "  Batch 1,600  of  11,422.    Elapsed: 0:06:39.\n",
      "  Batch 1,650  of  11,422.    Elapsed: 0:06:51.\n",
      "  Batch 1,700  of  11,422.    Elapsed: 0:07:03.\n",
      "  Batch 1,750  of  11,422.    Elapsed: 0:07:16.\n",
      "  Batch 1,800  of  11,422.    Elapsed: 0:07:28.\n",
      "  Batch 1,850  of  11,422.    Elapsed: 0:07:41.\n",
      "  Batch 1,900  of  11,422.    Elapsed: 0:07:53.\n",
      "  Batch 1,950  of  11,422.    Elapsed: 0:08:06.\n",
      "  Batch 2,000  of  11,422.    Elapsed: 0:08:18.\n",
      "  Batch 2,050  of  11,422.    Elapsed: 0:08:31.\n",
      "  Batch 2,100  of  11,422.    Elapsed: 0:08:43.\n",
      "  Batch 2,150  of  11,422.    Elapsed: 0:08:56.\n",
      "  Batch 2,200  of  11,422.    Elapsed: 0:09:08.\n",
      "  Batch 2,250  of  11,422.    Elapsed: 0:09:21.\n",
      "  Batch 2,300  of  11,422.    Elapsed: 0:09:33.\n",
      "  Batch 2,350  of  11,422.    Elapsed: 0:09:45.\n",
      "  Batch 2,400  of  11,422.    Elapsed: 0:09:58.\n",
      "  Batch 2,450  of  11,422.    Elapsed: 0:10:10.\n",
      "  Batch 2,500  of  11,422.    Elapsed: 0:10:23.\n",
      "  Batch 2,550  of  11,422.    Elapsed: 0:10:35.\n",
      "  Batch 2,600  of  11,422.    Elapsed: 0:10:48.\n",
      "  Batch 2,650  of  11,422.    Elapsed: 0:11:00.\n",
      "  Batch 2,700  of  11,422.    Elapsed: 0:11:13.\n",
      "  Batch 2,750  of  11,422.    Elapsed: 0:11:25.\n",
      "  Batch 2,800  of  11,422.    Elapsed: 0:11:38.\n",
      "  Batch 2,850  of  11,422.    Elapsed: 0:11:50.\n",
      "  Batch 2,900  of  11,422.    Elapsed: 0:12:02.\n",
      "  Batch 2,950  of  11,422.    Elapsed: 0:12:15.\n",
      "  Batch 3,000  of  11,422.    Elapsed: 0:12:27.\n",
      "  Batch 3,050  of  11,422.    Elapsed: 0:12:40.\n",
      "  Batch 3,100  of  11,422.    Elapsed: 0:12:52.\n",
      "  Batch 3,150  of  11,422.    Elapsed: 0:13:05.\n",
      "  Batch 3,200  of  11,422.    Elapsed: 0:13:17.\n",
      "  Batch 3,250  of  11,422.    Elapsed: 0:13:30.\n",
      "  Batch 3,300  of  11,422.    Elapsed: 0:13:42.\n",
      "  Batch 3,350  of  11,422.    Elapsed: 0:13:54.\n",
      "  Batch 3,400  of  11,422.    Elapsed: 0:14:07.\n",
      "  Batch 3,450  of  11,422.    Elapsed: 0:14:19.\n",
      "  Batch 3,500  of  11,422.    Elapsed: 0:14:32.\n",
      "  Batch 3,550  of  11,422.    Elapsed: 0:14:44.\n",
      "  Batch 3,600  of  11,422.    Elapsed: 0:14:57.\n",
      "  Batch 3,650  of  11,422.    Elapsed: 0:15:09.\n",
      "  Batch 3,700  of  11,422.    Elapsed: 0:15:22.\n",
      "  Batch 3,750  of  11,422.    Elapsed: 0:15:34.\n",
      "  Batch 3,800  of  11,422.    Elapsed: 0:15:46.\n",
      "  Batch 3,850  of  11,422.    Elapsed: 0:15:59.\n",
      "  Batch 3,900  of  11,422.    Elapsed: 0:16:11.\n",
      "  Batch 3,950  of  11,422.    Elapsed: 0:16:24.\n",
      "  Batch 4,000  of  11,422.    Elapsed: 0:16:36.\n",
      "  Batch 4,050  of  11,422.    Elapsed: 0:16:49.\n",
      "  Batch 4,100  of  11,422.    Elapsed: 0:17:01.\n",
      "  Batch 4,150  of  11,422.    Elapsed: 0:17:13.\n",
      "  Batch 4,200  of  11,422.    Elapsed: 0:17:26.\n",
      "  Batch 4,250  of  11,422.    Elapsed: 0:17:38.\n",
      "  Batch 4,300  of  11,422.    Elapsed: 0:17:51.\n",
      "  Batch 4,350  of  11,422.    Elapsed: 0:18:03.\n",
      "  Batch 4,400  of  11,422.    Elapsed: 0:18:16.\n",
      "  Batch 4,450  of  11,422.    Elapsed: 0:18:28.\n",
      "  Batch 4,500  of  11,422.    Elapsed: 0:18:40.\n",
      "  Batch 4,550  of  11,422.    Elapsed: 0:18:53.\n",
      "  Batch 4,600  of  11,422.    Elapsed: 0:19:05.\n",
      "  Batch 4,650  of  11,422.    Elapsed: 0:19:18.\n",
      "  Batch 4,700  of  11,422.    Elapsed: 0:19:30.\n",
      "  Batch 4,750  of  11,422.    Elapsed: 0:19:43.\n",
      "  Batch 4,800  of  11,422.    Elapsed: 0:19:55.\n",
      "  Batch 4,850  of  11,422.    Elapsed: 0:20:07.\n",
      "  Batch 4,900  of  11,422.    Elapsed: 0:20:20.\n",
      "  Batch 4,950  of  11,422.    Elapsed: 0:20:32.\n",
      "  Batch 5,000  of  11,422.    Elapsed: 0:20:45.\n",
      "  Batch 5,050  of  11,422.    Elapsed: 0:20:57.\n",
      "  Batch 5,100  of  11,422.    Elapsed: 0:21:10.\n",
      "  Batch 5,150  of  11,422.    Elapsed: 0:21:22.\n",
      "  Batch 5,200  of  11,422.    Elapsed: 0:21:34.\n",
      "  Batch 5,250  of  11,422.    Elapsed: 0:21:47.\n",
      "  Batch 5,300  of  11,422.    Elapsed: 0:21:59.\n",
      "  Batch 5,350  of  11,422.    Elapsed: 0:22:12.\n",
      "  Batch 5,400  of  11,422.    Elapsed: 0:22:24.\n",
      "  Batch 5,450  of  11,422.    Elapsed: 0:22:37.\n",
      "  Batch 5,500  of  11,422.    Elapsed: 0:22:49.\n",
      "  Batch 5,550  of  11,422.    Elapsed: 0:23:01.\n",
      "  Batch 5,600  of  11,422.    Elapsed: 0:23:14.\n",
      "  Batch 5,650  of  11,422.    Elapsed: 0:23:26.\n",
      "  Batch 5,700  of  11,422.    Elapsed: 0:23:39.\n",
      "  Batch 5,750  of  11,422.    Elapsed: 0:23:51.\n",
      "  Batch 5,800  of  11,422.    Elapsed: 0:24:04.\n",
      "  Batch 5,850  of  11,422.    Elapsed: 0:24:16.\n",
      "  Batch 5,900  of  11,422.    Elapsed: 0:24:28.\n",
      "  Batch 5,950  of  11,422.    Elapsed: 0:24:41.\n",
      "  Batch 6,000  of  11,422.    Elapsed: 0:24:53.\n",
      "  Batch 6,050  of  11,422.    Elapsed: 0:25:06.\n",
      "  Batch 6,100  of  11,422.    Elapsed: 0:25:18.\n",
      "  Batch 6,150  of  11,422.    Elapsed: 0:25:31.\n",
      "  Batch 6,200  of  11,422.    Elapsed: 0:25:43.\n",
      "  Batch 6,250  of  11,422.    Elapsed: 0:25:56.\n",
      "  Batch 6,300  of  11,422.    Elapsed: 0:26:08.\n",
      "  Batch 6,350  of  11,422.    Elapsed: 0:26:21.\n",
      "  Batch 6,400  of  11,422.    Elapsed: 0:26:33.\n",
      "  Batch 6,450  of  11,422.    Elapsed: 0:26:45.\n",
      "  Batch 6,500  of  11,422.    Elapsed: 0:26:58.\n",
      "  Batch 6,550  of  11,422.    Elapsed: 0:27:10.\n",
      "  Batch 6,600  of  11,422.    Elapsed: 0:27:23.\n",
      "  Batch 6,650  of  11,422.    Elapsed: 0:27:35.\n",
      "  Batch 6,700  of  11,422.    Elapsed: 0:27:48.\n",
      "  Batch 6,750  of  11,422.    Elapsed: 0:28:00.\n",
      "  Batch 6,800  of  11,422.    Elapsed: 0:28:13.\n",
      "  Batch 6,850  of  11,422.    Elapsed: 0:28:25.\n",
      "  Batch 6,900  of  11,422.    Elapsed: 0:28:38.\n",
      "  Batch 6,950  of  11,422.    Elapsed: 0:28:50.\n",
      "  Batch 7,000  of  11,422.    Elapsed: 0:29:03.\n",
      "  Batch 7,050  of  11,422.    Elapsed: 0:29:15.\n",
      "  Batch 7,100  of  11,422.    Elapsed: 0:29:28.\n",
      "  Batch 7,150  of  11,422.    Elapsed: 0:29:40.\n",
      "  Batch 7,200  of  11,422.    Elapsed: 0:29:53.\n",
      "  Batch 7,250  of  11,422.    Elapsed: 0:30:05.\n",
      "  Batch 7,300  of  11,422.    Elapsed: 0:30:18.\n",
      "  Batch 7,350  of  11,422.    Elapsed: 0:30:30.\n",
      "  Batch 7,400  of  11,422.    Elapsed: 0:30:43.\n",
      "  Batch 7,450  of  11,422.    Elapsed: 0:30:55.\n",
      "  Batch 7,500  of  11,422.    Elapsed: 0:31:08.\n",
      "  Batch 7,550  of  11,422.    Elapsed: 0:31:20.\n",
      "  Batch 7,600  of  11,422.    Elapsed: 0:31:33.\n",
      "  Batch 7,650  of  11,422.    Elapsed: 0:31:45.\n",
      "  Batch 7,700  of  11,422.    Elapsed: 0:31:57.\n",
      "  Batch 7,750  of  11,422.    Elapsed: 0:32:10.\n",
      "  Batch 7,800  of  11,422.    Elapsed: 0:32:22.\n",
      "  Batch 7,850  of  11,422.    Elapsed: 0:32:35.\n",
      "  Batch 7,900  of  11,422.    Elapsed: 0:32:47.\n",
      "  Batch 7,950  of  11,422.    Elapsed: 0:33:00.\n",
      "  Batch 8,000  of  11,422.    Elapsed: 0:33:12.\n",
      "  Batch 8,050  of  11,422.    Elapsed: 0:33:25.\n",
      "  Batch 8,100  of  11,422.    Elapsed: 0:33:37.\n",
      "  Batch 8,150  of  11,422.    Elapsed: 0:33:50.\n",
      "  Batch 8,200  of  11,422.    Elapsed: 0:34:02.\n",
      "  Batch 8,250  of  11,422.    Elapsed: 0:34:15.\n",
      "  Batch 8,300  of  11,422.    Elapsed: 0:34:27.\n",
      "  Batch 8,350  of  11,422.    Elapsed: 0:34:40.\n",
      "  Batch 8,400  of  11,422.    Elapsed: 0:34:52.\n",
      "  Batch 8,450  of  11,422.    Elapsed: 0:35:05.\n",
      "  Batch 8,500  of  11,422.    Elapsed: 0:35:17.\n",
      "  Batch 8,550  of  11,422.    Elapsed: 0:35:30.\n",
      "  Batch 8,600  of  11,422.    Elapsed: 0:35:42.\n",
      "  Batch 8,650  of  11,422.    Elapsed: 0:35:55.\n",
      "  Batch 8,700  of  11,422.    Elapsed: 0:36:07.\n",
      "  Batch 8,750  of  11,422.    Elapsed: 0:36:20.\n",
      "  Batch 8,800  of  11,422.    Elapsed: 0:36:32.\n",
      "  Batch 8,850  of  11,422.    Elapsed: 0:36:45.\n",
      "  Batch 8,900  of  11,422.    Elapsed: 0:36:57.\n",
      "  Batch 8,950  of  11,422.    Elapsed: 0:37:10.\n",
      "  Batch 9,000  of  11,422.    Elapsed: 0:37:22.\n",
      "  Batch 9,050  of  11,422.    Elapsed: 0:37:35.\n",
      "  Batch 9,100  of  11,422.    Elapsed: 0:37:47.\n",
      "  Batch 9,150  of  11,422.    Elapsed: 0:38:00.\n",
      "  Batch 9,200  of  11,422.    Elapsed: 0:38:12.\n",
      "  Batch 9,250  of  11,422.    Elapsed: 0:38:25.\n",
      "  Batch 9,300  of  11,422.    Elapsed: 0:38:37.\n",
      "  Batch 9,350  of  11,422.    Elapsed: 0:38:50.\n",
      "  Batch 9,400  of  11,422.    Elapsed: 0:39:02.\n",
      "  Batch 9,450  of  11,422.    Elapsed: 0:39:15.\n",
      "  Batch 9,500  of  11,422.    Elapsed: 0:39:27.\n",
      "  Batch 9,550  of  11,422.    Elapsed: 0:39:40.\n",
      "  Batch 9,600  of  11,422.    Elapsed: 0:39:52.\n",
      "  Batch 9,650  of  11,422.    Elapsed: 0:40:04.\n",
      "  Batch 9,700  of  11,422.    Elapsed: 0:40:17.\n",
      "  Batch 9,750  of  11,422.    Elapsed: 0:40:29.\n",
      "  Batch 9,800  of  11,422.    Elapsed: 0:40:42.\n",
      "  Batch 9,850  of  11,422.    Elapsed: 0:40:54.\n",
      "  Batch 9,900  of  11,422.    Elapsed: 0:41:07.\n",
      "  Batch 9,950  of  11,422.    Elapsed: 0:41:19.\n",
      "  Batch 10,000  of  11,422.    Elapsed: 0:41:32.\n",
      "  Batch 10,050  of  11,422.    Elapsed: 0:41:44.\n",
      "  Batch 10,100  of  11,422.    Elapsed: 0:41:57.\n",
      "  Batch 10,150  of  11,422.    Elapsed: 0:42:09.\n",
      "  Batch 10,200  of  11,422.    Elapsed: 0:42:22.\n",
      "  Batch 10,250  of  11,422.    Elapsed: 0:42:34.\n",
      "  Batch 10,300  of  11,422.    Elapsed: 0:42:47.\n",
      "  Batch 10,350  of  11,422.    Elapsed: 0:42:59.\n",
      "  Batch 10,400  of  11,422.    Elapsed: 0:43:12.\n",
      "  Batch 10,450  of  11,422.    Elapsed: 0:43:24.\n",
      "  Batch 10,500  of  11,422.    Elapsed: 0:43:37.\n",
      "  Batch 10,550  of  11,422.    Elapsed: 0:43:49.\n",
      "  Batch 10,600  of  11,422.    Elapsed: 0:44:02.\n",
      "  Batch 10,650  of  11,422.    Elapsed: 0:44:14.\n",
      "  Batch 10,700  of  11,422.    Elapsed: 0:44:27.\n",
      "  Batch 10,750  of  11,422.    Elapsed: 0:44:39.\n",
      "  Batch 10,800  of  11,422.    Elapsed: 0:44:52.\n",
      "  Batch 10,850  of  11,422.    Elapsed: 0:45:04.\n",
      "  Batch 10,900  of  11,422.    Elapsed: 0:45:16.\n",
      "  Batch 10,950  of  11,422.    Elapsed: 0:45:29.\n",
      "  Batch 11,000  of  11,422.    Elapsed: 0:45:41.\n",
      "  Batch 11,050  of  11,422.    Elapsed: 0:45:54.\n",
      "  Batch 11,100  of  11,422.    Elapsed: 0:46:06.\n",
      "  Batch 11,150  of  11,422.    Elapsed: 0:46:19.\n",
      "  Batch 11,200  of  11,422.    Elapsed: 0:46:31.\n",
      "  Batch 11,250  of  11,422.    Elapsed: 0:46:44.\n",
      "  Batch 11,300  of  11,422.    Elapsed: 0:46:56.\n",
      "  Batch 11,350  of  11,422.    Elapsed: 0:47:09.\n",
      "  Batch 11,400  of  11,422.    Elapsed: 0:47:21.\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:47:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation Loss: 0.36\n",
      "  Validation took: 0:01:43\n",
      "\n",
      "Training complete!\n",
      "Total training took 1:38:13 (h:mm:ss)\n",
      "Predicting labels for 1,407 total test sentences...\n",
      "\n",
      "--- [전체 데이터셋] 테스트 결과 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.85      0.91      0.88     18987\n",
      " 비도덕성 있음 (1)       0.93      0.89      0.91     26011\n",
      "\n",
      "    accuracy                           0.90     44998\n",
      "   macro avg       0.89      0.90      0.89     44998\n",
      "weighted avg       0.90      0.90      0.90     44998\n",
      "\n",
      "    DONE (Total Test).\n",
      "\n",
      "\n",
      "--- [유형별 상세 테스트 결과] ---\n",
      "\n",
      "--- TEST 데이터를 모든 유형을 기준으로 분리 중... ---\n",
      "  - 유형: CENSURE              | 샘플 수: 19,866\n",
      "  - 유형: ABUSE                | 샘플 수: 1,474\n",
      "  - 유형: HATE                 | 샘플 수: 9,222\n",
      "  - 유형: VIOLENCE             | 샘플 수: 2,167\n",
      "  - 유형: CRIME                | 샘플 수: 1,075\n",
      "  - 유형: SEXUAL               | 샘플 수: 2,737\n",
      "  - 유형: DISCRIMINATION       | 샘플 수: 2,664\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: CENSURE ---\n",
      "총 샘플 수: 19,866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.90      0.95     19866\n",
      "\n",
      "    accuracy                           0.90     19866\n",
      "   macro avg       0.50      0.45      0.47     19866\n",
      "weighted avg       1.00      0.90      0.95     19866\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: ABUSE ---\n",
      "총 샘플 수: 1,474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.95      0.98      1474\n",
      "\n",
      "    accuracy                           0.95      1474\n",
      "   macro avg       0.50      0.48      0.49      1474\n",
      "weighted avg       1.00      0.95      0.98      1474\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: HATE ---\n",
      "총 샘플 수: 9,222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.93      0.97      9222\n",
      "\n",
      "    accuracy                           0.93      9222\n",
      "   macro avg       0.50      0.47      0.48      9222\n",
      "weighted avg       1.00      0.93      0.97      9222\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: VIOLENCE ---\n",
      "총 샘플 수: 2,167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.94      0.97      2167\n",
      "\n",
      "    accuracy                           0.94      2167\n",
      "   macro avg       0.50      0.47      0.48      2167\n",
      "weighted avg       1.00      0.94      0.97      2167\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: CRIME ---\n",
      "총 샘플 수: 1,075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.81      0.90      1075\n",
      "\n",
      "    accuracy                           0.81      1075\n",
      "   macro avg       0.50      0.41      0.45      1075\n",
      "weighted avg       1.00      0.81      0.90      1075\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: SEXUAL ---\n",
      "총 샘플 수: 2,737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.86      0.92      2737\n",
      "\n",
      "    accuracy                           0.86      2737\n",
      "   macro avg       0.50      0.43      0.46      2737\n",
      "weighted avg       1.00      0.86      0.92      2737\n",
      "\n",
      "\n",
      "--- [유형별 테스트 결과] 유형: DISCRIMINATION ---\n",
      "총 샘플 수: 2,664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " 비도덕성 없음 (0)       0.00      0.00      0.00         0\n",
      " 비도덕성 있음 (1)       1.00      0.91      0.95      2664\n",
      "\n",
      "    accuracy                           0.91      2664\n",
      "   macro avg       0.50      0.46      0.48      2664\n",
      "weighted avg       1.00      0.91      0.95      2664\n",
      "\n",
      "\n",
      "--- 유형별 상세 테스트 종료 ---\n",
      "Saving model to ./model_checkpoint\n",
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'ElectraTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./model_checkpoint\n",
      "'이런건 걍 돈없고 멍청한 전라도 여자들 겨냥한 상술이지' 은/는 폭력성이 포함된 문장입니다\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "\n",
    "from dataloader import Dataset\n",
    "from model import Models\n",
    "from transformers import BertTokenizer\n",
    "from utils import split_sentence\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def file_upload():\n",
    "    return render_template('load_file.html')\n",
    "    \n",
    "@app.route('/isViolence', methods = ['POST', 'GET'])\n",
    "def Predict():\n",
    "    if request.method == 'POST':\n",
    "        input_text = request.files['파일'].read().decode('utf-8') # 파일 불러오기\n",
    "        input_text = input_text.split('\\r\\n')\n",
    "        \n",
    "        if input_text == None:\n",
    "            return render_template('isViolence.html', Output = '')\n",
    "\n",
    "        sentences = split_sentence(input_text)  # 채팅 목록을 문장 단위로 분리\n",
    "        # print(sentences)\n",
    "        result = 0\n",
    "        for i, sentence in enumerate(sentences[:10000]):\n",
    "            if (i+1) % 1000 == 0:\n",
    "                print(f\"{i+1}번째 실행 중...\")\n",
    "            result += model.inference(sentence[-1])[1]\n",
    "        \n",
    "        ModelOutput = f\"해당 채팅방의 폭력성 대화 비율은 {round((result / len(sentences)) * 100, 2)}% 입니다\"\n",
    "        print(ModelOutput)\n",
    "        return render_template('isViolence.html', Output = ModelOutput)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    train_file_path = './data/train.csv'\n",
    "    valid_file_path = './data/val.csv'\n",
    "    test_file_path = './data/test.csv' \n",
    "    model_save_dir = './model_checkpoint'       # 모델 저장 디렉토리 경로\n",
    "    model_load_dir = './model_checkpoint'       # 모델 불러오기 디렉토리 경로\n",
    "\n",
    "    TRAIN_DATA_LIMIT = 365500\n",
    "\n",
    "    # # 1. 단일 Dataset 인스턴스 생성 및 데이터 로드\n",
    "    dataset = Dataset()\n",
    "    dataset.set_dataset('train', file_path=train_file_path, max_rows=TRAIN_DATA_LIMIT)\n",
    "    dataset.set_dataset('valid', file_path=valid_file_path)\n",
    "    dataset.set_dataset('test', file_path=test_file_path)\n",
    "\n",
    "    # # 2. Models 인스턴스 생성 및 Dataset 연결\n",
    "    # Models 인스턴스를 만들 때, dataset 객체를 인수로 전달합니다.\n",
    "    model = Models('koelectra', num_labels = 2, dataset_instance=dataset) \n",
    "    \n",
    "    # # 3. 모델 정의 및 토크나이저 설정\n",
    "    # model.BERT()를 호출하여 모델을 생성하고, 반환된 토크나이저를 dataset에 설정합니다.\n",
    "    tokenizer_for_training = model.BERT()  \n",
    "    dataset.set_tokenizer(tokenizer_for_training)\n",
    "    \n",
    "    print(dataset.get_tokenizer())\n",
    "    \n",
    "    # # 4. 데이터 로더 생성 (이제 올바른 토크나이저를 사용)\n",
    "    train, valid, test = dataset.get_dataloader()  \n",
    "    \n",
    "    model.about_model()\n",
    "    model.train(train, valid, epochs = 2, project_title=None) \n",
    "    model.test(test)\n",
    "    model.save_model(model_save_dir)\n",
    "\n",
    "    # # 5. 추론 및 웹 서버용 모델 로드 (새로운 인스턴스 생성 및 로드)\n",
    "    # 추론용 모델도 동일한 dataset 인스턴스를 사용하도록 연결\n",
    "    web_model = Models('koelectra', num_labels = 2, dataset_instance=dataset)\n",
    "    web_model.load_model(load_dir_path=model_load_dir)\n",
    "    \n",
    "    # # 6. 단일 문장 추론 테스트\n",
    "    sentence, prediction = web_model.inference('이런건 걍 돈없고 멍청한 전라도 여자들 겨냥한 상술이지')\n",
    "    print(f\"'{sentence}' 은/는 폭력성이 포함된 문장입니다\" if prediction == 1 else f\"'{sentence}' 은/는 폭력성이 포함되지 않은 문장입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663ee29-2960-4b4a-81b4-60ea108795eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
