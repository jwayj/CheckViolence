{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e76c67-cd9e-4f18-b136-4ac48ba81c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n",
      "max_length : 128\n",
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at snunlp/KR-BERT-char16424 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./model_checkpoint\n",
      "✅ 모델 (KRBERT) 및 토크나이저 로드 완료.\n",
      "--------------------------------------------------\n",
      "Embedding Weight Shape: torch.Size([16424, 768])\n",
      "\n",
      "--- 특정 단어의 임베딩 벡터 확인 ---\n",
      "'한국' (ID: 145): [-0.0562454   0.0108557  -0.05825476 -0.00025469  0.01125608]\n",
      "'사람' (ID: 640): [-0.03931377  0.03173213 -0.00827596  0.04252414 -0.01495786]\n",
      "'여자' (ID: 1011): [-0.02547332 -0.02484689 -0.04527205 -0.0606334   0.04343596]\n",
      "'남자' (ID: 1029): [-0.05862902 -0.00043198 -0.02857768 -0.01635378  0.03356219]\n",
      "'루저' (ID: 1): [ 0.01492126  0.04595394 -0.02212146  0.01701351 -0.01845635]\n",
      "'폭력' (ID: 4550): [-0.04072202  0.04634293 -0.08216351 -0.02248642 -0.00760159]\n",
      "'[CLS]' (ID: 2): [-0.01717631  0.03672351 -0.00662045 -0.01008655  0.02187421]\n",
      "'[SEP]' (ID: 3): [-0.00344839  0.05116087 -0.01009995  0.00629113 -0.01234006]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import os\n",
    "import numpy as np\n",
    "from dataloader import Dataset\n",
    "from model import Models\n",
    "\n",
    "\n",
    "def check_safetensors_embedding_weights(model_load_dir='./model_checkpoint', model_name='krbert'):\n",
    "    \"\"\"\n",
    "    로드된 BERT 모델의 Embedding 레이어에서 특정 단어의 가중치를 확인합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Models 인스턴스 생성 및 로드\n",
    "        dataset_instance = Dataset() # dataloader.py에 정의된 클래스 사용\n",
    "        \n",
    "        # Models 클래스는 __init__에서 dataset_instance를 받거나 내부적으로 생성합니다.\n",
    "        web_model = Models(model_name=model_name, num_labels=2, dataset_instance=dataset_instance)\n",
    "        \n",
    "        # load_model을 호출하여 모델 가중치와 토크나이저를 로드합니다.\n",
    "        # 이 과정에서 model_checkpoint 디렉토리의 model.safetensors 파일을 읽습니다.\n",
    "        web_model.load_model(load_dir_path=model_load_dir)\n",
    "        \n",
    "        # 로드된 모델 객체와 토크나이저를 가져옵니다.\n",
    "        model = web_model.model\n",
    "        tokenizer = web_model.tokenizer\n",
    "\n",
    "        print(f\"✅ 모델 ({model_name.upper()}) 및 토크나이저 로드 완료.\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # 2. 임베딩 가중치 접근\n",
    "        # BERT 모델에서 단어 임베딩 레이어는 'embeddings.word_embeddings.weight'에 있습니다.\n",
    "        word_embeddings = model.bert.embeddings.word_embeddings.weight\n",
    "        \n",
    "        # 임베딩 가중치의 크기 출력 (e.g., [Vocab_Size, Hidden_Size])\n",
    "        print(f\"Embedding Weight Shape: {word_embeddings.shape}\")\n",
    "        \n",
    "        # 3. 특정 단어의 임베딩 벡터 확인\n",
    "        # KR-BERT의 주요 토큰 몇 개를 확인합니다.\n",
    "        \n",
    "        # 확인할 단어 목록 (KR-BERT의 경우 Character/Subword 기반)\n",
    "        test_words = [\"한국\", \"사람\", \"여자\", \"남자\", \"루저\", \"폭력\",  \"[CLS]\", \"[SEP]\"]\n",
    "        \n",
    "        print(\"\\n--- 특정 단어의 임베딩 벡터 확인 ---\")\n",
    "        \n",
    "        for word in test_words:\n",
    "            # 토크나이저를 이용해 단어의 ID(index)를 얻습니다.\n",
    "            try:\n",
    "                # KR-BERT 토크나이저는 단어/문자를 ID로 변환합니다.\n",
    "                token_id = tokenizer.convert_tokens_to_ids(word)\n",
    "                \n",
    "                # 해당 ID의 임베딩 가중치를 추출합니다. (텐서를 CPU로 이동 후 NumPy 변환)\n",
    "                embedding_vector = word_embeddings[token_id].detach().cpu().numpy()\n",
    "                \n",
    "                # 임베딩 벡터의 처음 5개 차원만 출력\n",
    "                print(f\"'{word}' (ID: {token_id}): {embedding_vector[:5]}\")\n",
    "            \n",
    "            except KeyError:\n",
    "                print(f\"Warning: '{word}'는 토크나이저의 어휘 목록에 없습니다.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing word '{word}': {e}\")\n",
    "                \n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 에러: 모델 저장 디렉토리 '{model_load_dir}'를 찾을 수 없습니다.\")\n",
    "        print(\"model.safetensors 파일이 해당 디렉토리에 있는지 확인하십시오.\")\n",
    "    except AttributeError as e:\n",
    "        print(f\"❌ 에러: 모델 로드 또는 접근 중 오류 발생. 모델 객체에 문제가 있을 수 있습니다.\")\n",
    "        print(f\"상세 에러: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 예상치 못한 오류 발생: {e}\")\n",
    "\n",
    "# ==========================================================\n",
    "# TODO: 모델 가중치를 확인하려면 실제 모델 저장 경로를 지정해야 합니다.\n",
    "model_load_directory = './model_checkpoint' \n",
    "# ==========================================================\n",
    "\n",
    "# 함수 실행\n",
    "check_safetensors_embedding_weights(model_load_dir=model_load_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f43c3-1e0d-4488-b537-e5d0367091d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
