{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ab1f3e-da91-4b16-9694-1f1aa8a30524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ë””ë²„ê¹… í™˜ê²½ ì„¤ì • ===\n",
      "ì‚¬ìš© ê°€ëŠ¥ GPU ìˆ˜: 2\n",
      "**ìµœì¢… í•™ìŠµ ì¥ì¹˜**: cuda:0\n",
      "ë°°ì¹˜ í¬ê¸°: 8\n",
      "--------------------------------\n",
      "\n",
      "[ë°ì´í„° ë¡œë“œ] stage1_data.csvì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "âœ… í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìœ ë‹ˆì½”ë“œ ì œì–´ ë¬¸ì ë° ì†ìƒëœ ë¬¸ì ì •ì œ ì¤‘...\n",
      "ì´ ë°ì´í„° ìˆ˜: 199999\n",
      "ë ˆì´ë¸” ë¶„í¬:\n",
      "label\n",
      "0    100000\n",
      "1     99999\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f2f974129e41ffb344c43c965fef18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/179999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ëª¨ë¸ ë¡œë“œ] ì €ì¥ëœ ëª¨ë¸ '/home/kds/pytorch/CheckViolence/finalProject/model_checkpoint' ë¡œë“œ ì¤‘...\n",
      "âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ë° ë‹¨ì¼ ì¥ì¹˜ ì´ë™ ì„±ê³µ.\n",
      "--- LoRA ì ìš© ëª¨ë¸ ì •ë³´ ---\n",
      "trainable params: 443,906 || all params: 99,100,420 || trainable%: 0.4479\n",
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22500/22500 [1:30:41<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Time: 1:30:41\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22500/22500 [1:31:04<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training Time: 1:31:05\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22500/22500 [1:31:07<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training Time: 1:31:08\n",
      "\n",
      "Training complete! (ìˆ˜ë™ ë£¨í”„)\n",
      "\n",
      "=== 6. LoRA ì–´ëŒ‘í„° ì €ì¥ ===\n",
      "âœ… LoRA ì–´ëŒ‘í„°ê°€ '/home/kds/pytorch/CheckViolence/finalProject/peft_model_checkpoint'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ëª¨ë“  í›ˆë ¨ ë° ì €ì¥ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "=== ğŸ§ª ì¶”ë¡  ë° í‰ê°€ ì‹œì‘ ===\n",
      "**ìµœì¢… ì¶”ë¡  ì¥ì¹˜**: cuda:0\n",
      "âœ… LoRA ì–´ëŒ‘í„°ê°€ Base Modelì— ì„±ê³µì ìœ¼ë¡œ ë³‘í•©ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[ë°ì´í„° ë¡œë“œ] ./data/test.csvì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "âœ… í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìœ ë‹ˆì½”ë“œ ì œì–´ ë¬¸ì ë° ì†ìƒëœ ë¬¸ì ì •ì œ ì¤‘...\n",
      "ì´ ë°ì´í„° ìˆ˜: 44998\n",
      "ë ˆì´ë¸” ë¶„í¬:\n",
      "label\n",
      "1    26011\n",
      "0    18987\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123144b634ff4ff7a8cdaf5d719de296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì¶”ë¡ ] ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1407/1407 [08:23<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== ğŸ“Š ë‹¤ì¤‘ ìœ í˜•ë³„ ë¶„ë¥˜ ê²°ê³¼ (ì½¤ë§ˆ ë¶„ë¦¬) ===\n",
      "\n",
      "[ì „ì²´ ë°ì´í„°ì…‹ ë¶„ë¥˜ ë³´ê³ ì„œ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " ë¹„ë„ë•ì„± ì—†ìŒ (0)       0.73      0.53      0.61     18987\n",
      " ë¹„ë„ë•ì„± ìˆìŒ (1)       0.71      0.85      0.78     26011\n",
      "\n",
      "    accuracy                           0.72     44998\n",
      "   macro avg       0.72      0.69      0.69     44998\n",
      "weighted avg       0.72      0.72      0.71     44998\n",
      "\n",
      "\n",
      "--- [ìœ í˜•ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼] ìœ í˜•: ABUSE ---\n",
      "ì´ ìƒ˜í”Œ ìˆ˜: 1,474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " ë¹„ë„ë•ì„± ì—†ìŒ (0)       0.00      0.00      0.00         0\n",
      " ë¹„ë„ë•ì„± ìˆìŒ (1)       1.00      0.89      0.94      1474\n",
      "\n",
      "    accuracy                           0.89      1474\n",
      "   macro avg       0.50      0.44      0.47      1474\n",
      "weighted avg       1.00      0.89      0.94      1474\n",
      "\n",
      "\n",
      "--- [ìœ í˜•ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼] ìœ í˜•: CENSURE ---\n",
      "ì´ ìƒ˜í”Œ ìˆ˜: 19,866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " ë¹„ë„ë•ì„± ì—†ìŒ (0)       0.00      0.00      0.00         0\n",
      " ë¹„ë„ë•ì„± ìˆìŒ (1)       1.00      0.87      0.93     19866\n",
      "\n",
      "    accuracy                           0.87     19866\n",
      "   macro avg       0.50      0.43      0.47     19866\n",
      "weighted avg       1.00      0.87      0.93     19866\n",
      "\n",
      "\n",
      "--- [ìœ í˜•ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼] ìœ í˜•: CRIME ---\n",
      "ì´ ìƒ˜í”Œ ìˆ˜: 1,075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " ë¹„ë„ë•ì„± ì—†ìŒ (0)       0.00      0.00      0.00         0\n",
      " ë¹„ë„ë•ì„± ìˆìŒ (1)       1.00      0.78      0.88      1075\n",
      "\n",
      "    accuracy                           0.78      1075\n",
      "   macro avg       0.50      0.39      0.44      1075\n",
      "weighted avg       1.00      0.78      0.88      1075\n",
      "\n",
      "\n",
      "--- [ìœ í˜•ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼] ìœ í˜•: DISCRIMINATION ---\n",
      "ì´ ìƒ˜í”Œ ìˆ˜: 2,664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " ë¹„ë„ë•ì„± ì—†ìŒ (0)       0.00      0.00      0.00         0\n",
      " ë¹„ë„ë•ì„± ìˆìŒ (1)       1.00      0.91      0.95      2664\n",
      "\n",
      "    accuracy                           0.91      2664\n",
      "   macro avg       0.50      0.46      0.48      2664\n",
      "weighted avg       1.00      0.91      0.95      2664\n",
      "\n",
      "\n",
      "--- [ìœ í˜•ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼] ìœ í˜•: HATE ---\n",
      "ì´ ìƒ˜í”Œ ìˆ˜: 9,222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " ë¹„ë„ë•ì„± ì—†ìŒ (0)       0.00      0.00      0.00         0\n",
      " ë¹„ë„ë•ì„± ìˆìŒ (1)       1.00      0.89      0.94      9222\n",
      "\n",
      "    accuracy                           0.89      9222\n",
      "   macro avg       0.50      0.45      0.47      9222\n",
      "weighted avg       1.00      0.89      0.94      9222\n",
      "\n",
      "\n",
      "--- [ìœ í˜•ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼] ìœ í˜•: IMMORAL_NONE ---\n",
      "ì´ ìƒ˜í”Œ ìˆ˜: 19,003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " ë¹„ë„ë•ì„± ì—†ìŒ (0)       1.00      0.53      0.69     18987\n",
      " ë¹„ë„ë•ì„± ìˆìŒ (1)       0.00      0.50      0.00        16\n",
      "\n",
      "    accuracy                           0.53     19003\n",
      "   macro avg       0.50      0.51      0.35     19003\n",
      "weighted avg       1.00      0.53      0.69     19003\n",
      "\n",
      "\n",
      "--- [ìœ í˜•ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼] ìœ í˜•: SEXUAL ---\n",
      "ì´ ìƒ˜í”Œ ìˆ˜: 2,737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " ë¹„ë„ë•ì„± ì—†ìŒ (0)       0.00      0.00      0.00         0\n",
      " ë¹„ë„ë•ì„± ìˆìŒ (1)       1.00      0.80      0.89      2737\n",
      "\n",
      "    accuracy                           0.80      2737\n",
      "   macro avg       0.50      0.40      0.44      2737\n",
      "weighted avg       1.00      0.80      0.89      2737\n",
      "\n",
      "\n",
      "--- [ìœ í˜•ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼] ìœ í˜•: VIOLENCE ---\n",
      "ì´ ìƒ˜í”Œ ìˆ˜: 2,167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " ë¹„ë„ë•ì„± ì—†ìŒ (0)       0.00      0.00      0.00         0\n",
      " ë¹„ë„ë•ì„± ìˆìŒ (1)       1.00      0.82      0.90      2167\n",
      "\n",
      "    accuracy                           0.82      2167\n",
      "   macro avg       0.50      0.41      0.45      2167\n",
      "weighted avg       1.00      0.82      0.90      2167\n",
      "\n",
      "================================\n",
      "âœ… ë‹¤ì¤‘ ìœ í˜•ë³„ ì¶”ë¡  ë° í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "# ----------------------------------------------------------------------\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# PyTorch ë° Hugging Face\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from datasets import Dataset as HFDataset\n",
    "\n",
    "# âœ¨ LoRA (PEFT)\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModel\n",
    "\n",
    "# âœ¨ ì„±ëŠ¥ ì§€í‘œ\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def format_time(elapsed):\n",
    "    \"\"\"\n",
    "    ê²½ê³¼ ì‹œê°„ì„ HH:MM:SS í˜•ì‹ìœ¼ë¡œ í¬ë§·\n",
    "    \"\"\"\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ (ìˆ˜ì •: ì¸ë±ìŠ¤ ì»¬ëŸ¼ ì•ˆì „ ì œê±° ë¡œì§ ì¶”ê°€)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# ğŸŒŸ ì¤‘ìš”: ê²½ë¡œ ì„¤ì •\n",
    "MODEL_LOAD_PATH = os.path.abspath('./model_checkpoint') \n",
    "LORA_SAVE_PATH = os.path.abspath('./peft_model_checkpoint')\n",
    "TEST_DATA_PATH = './data/test.csv' \n",
    "\n",
    "try:\n",
    "    # ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œì—ì„œ í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹œë„\n",
    "    tokenizer = BertTokenizer.from_pretrained(MODEL_LOAD_PATH)\n",
    "except Exception:\n",
    "    # ë¡œì»¬ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì›ë³¸ KR-BERT ê²½ë¡œë¡œ í´ë°± (í† í¬ë‚˜ì´ì € Vocab ì¼ì¹˜ë¥¼ ìœ„í•´)\n",
    "    print(\"ê²½ê³ : ë¡œì»¬ í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨, ì›ë³¸ KR-BERT ê²½ë¡œ ì‚¬ìš©\")\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"snunlp/KR-BERT-char16424\")\n",
    "\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "def load_and_preprocess_data(csv_path, is_training=True):\n",
    "    \"\"\"\n",
    "    CSV íŒŒì¼ ë¡œë“œ ë° Hugging Face Dataset ê°ì²´ë¡œ ë³€í™˜\n",
    "    \"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"'{csv_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    print(f\"\\n[ë°ì´í„° ë¡œë“œ] {csv_path}ì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "    except:\n",
    "        df = pd.read_csv(csv_path, encoding='cp949')\n",
    "        \n",
    "    # ğŸŒŸ ì»¬ëŸ¼ëª… ë§¤í•‘ (í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ë”°ë¼ ë‹¤ë¦„)\n",
    "    if is_training:\n",
    "        # í›ˆë ¨ ë°ì´í„° ì»¬ëŸ¼ëª… (stage1_data.csv ê¸°ì¤€)\n",
    "        text_col, label_col = 'content', 'label'\n",
    "    else: \n",
    "        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì»¬ëŸ¼ëª… (image_70b35e.png ê¸°ì¤€)\n",
    "        text_col, label_col = 'ë¬¸ì¥', 'ë¹„ë„ë•ì„± ì—¬ë¶€'\n",
    "        \n",
    "    required_cols = [text_col, label_col] + ([] if is_training else ['ìœ í˜•'])\n",
    "    \n",
    "    # í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì‚¬\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        raise ValueError(f\"CSV íŒŒì¼ì— ë‹¤ìŒ í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_cols}\")\n",
    "\n",
    "    df = df[required_cols].dropna().reset_index(drop=True)\n",
    "    \n",
    "    # ì»¬ëŸ¼ í†µì¼\n",
    "    df.columns = ['text', 'label'] + ([] if is_training else ['type'])\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë ˆì´ë¸” ë§¤í•‘ (FALSE=0, TRUE=1)\n",
    "    if not is_training and df['label'].dtype == object:\n",
    "        df['label'] = df['label'].astype(str).str.upper().map({'FALSE': 0, 'TRUE': 1}).fillna(-1)\n",
    "    \n",
    "    df['text'] = df['text'].astype(str)\n",
    "\n",
    "    # ğŸŒŸğŸŒŸğŸŒŸ ê°•ë ¥í•œ í…ìŠ¤íŠ¸ ì •ì œ ë¡œì§ ğŸŒŸğŸŒŸğŸŒŸ\n",
    "    print(\"âœ… í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìœ ë‹ˆì½”ë“œ ì œì–´ ë¬¸ì ë° ì†ìƒëœ ë¬¸ì ì •ì œ ì¤‘...\")\n",
    "    control_char_regex = r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F-\\x9F]'\n",
    "    df['text'] = df['text'].str.replace(r'@[\\w\\d#]+', ' ', regex=True)\n",
    "    df['text'] = df['text'].str.replace(control_char_regex, '', regex=True)\n",
    "    df['text'] = df['text'].str.replace(r'[^\\w\\s\\.\\,\\!\\?]', ' ', regex=True) \n",
    "    df['text'] = df['text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "    df = df[df['text'].str.strip().astype(bool)].reset_index(drop=True)\n",
    "    \n",
    "    # ğŸŒŸğŸŒŸğŸŒŸ ê°•ë ¥í•œ ë ˆì´ë¸” ì •ì œ ë¡œì§ ğŸŒŸğŸŒŸğŸŒŸ\n",
    "    valid_labels = {0, 1}\n",
    "    numeric_labels = pd.to_numeric(df['label'], errors='coerce')\n",
    "    \n",
    "    df_cleaned = df[numeric_labels.notna() & (numeric_labels == numeric_labels.astype(int))]\n",
    "    df_cleaned['label'] = df_cleaned['label'].astype(int)\n",
    "    \n",
    "    df_final = df_cleaned[df_cleaned['label'].isin(valid_labels)].reset_index(drop=True)\n",
    "    invalid_count = len(df) - len(df_final)\n",
    "    \n",
    "    if invalid_count > 0:\n",
    "        print(f\"âœ… ë ˆì´ë¸” ì •ì œ ì™„ë£Œ: ìœ íš¨í•˜ì§€ ì•Šì€ ê°’/ë ˆì´ë¸”({valid_labels} ì™¸) {invalid_count}ê°œ í–‰ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "    df = df_final\n",
    "    # ğŸŒŸğŸŒŸğŸŒŸ ë ˆì´ë¸” ì •ì œ ë¡œì§ ë ğŸŒŸğŸŒŸğŸŒŸ\n",
    "\n",
    "    hf_dataset = HFDataset.from_pandas(df)\n",
    "    print(f\"ì´ ë°ì´í„° ìˆ˜: {len(hf_dataset)}\")\n",
    "    print(f\"ë ˆì´ë¸” ë¶„í¬:\\n{df['label'].value_counts()}\")\n",
    "    \n",
    "    # ğŸŒŸğŸŒŸğŸŒŸ ì•ˆì „ ë¡œì§: ì¸ë±ìŠ¤ ì»¬ëŸ¼ ì œê±° ğŸŒŸğŸŒŸğŸŒŸ\n",
    "    if '__index_level_0__' in hf_dataset.column_names:\n",
    "        hf_dataset = hf_dataset.remove_columns(['__index_level_0__'])\n",
    "    # ğŸŒŸğŸŒŸğŸŒŸ ì•ˆì „ ë¡œì§ ë ğŸŒŸğŸŒŸğŸŒŸ\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ê²½ìš° 'type' ì»¬ëŸ¼ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³„ë„ ë°˜í™˜í•˜ì—¬ ì›ë³¸ ë§µí•‘ ìœ ì§€\n",
    "    if not is_training:\n",
    "        return hf_dataset, df['type'].tolist()\n",
    "        \n",
    "    return hf_dataset\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    í† í¬ë‚˜ì´ì§• í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. LoRA ëª¨ë¸ ë° ìˆ˜ë™ ë””ë²„ê¹… ë£¨í”„ ì„¤ì • (í›ˆë ¨)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def debug_lora_training(epochs=3, batch_size=8, save_path=LORA_SAVE_PATH):\n",
    "    \n",
    "    # 1. GPU ë° í™˜ê²½ ì„¤ì •\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    if torch.cuda.is_available():\n",
    "        DEVICE = torch.device(\"cuda:0\") # cuda:0 ì¥ì¹˜ ëª…ì‹œ\n",
    "    else:\n",
    "        DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "    print(f\"\\n=== ë””ë²„ê¹… í™˜ê²½ ì„¤ì • ===\")\n",
    "    print(f\"ì‚¬ìš© ê°€ëŠ¥ GPU ìˆ˜: {num_gpus}\")\n",
    "    print(f\"**ìµœì¢… í•™ìŠµ ì¥ì¹˜**: {DEVICE}\")\n",
    "    print(f\"ë°°ì¹˜ í¬ê¸°: {batch_size}\")\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "    # 2. ë°ì´í„° ì¤€ë¹„\n",
    "    raw_dataset = load_and_preprocess_data(csv_path='stage1_data.csv', is_training=True) \n",
    "    split_dataset = raw_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "    tokenized_train_dataset = split_dataset['train'].map(tokenize_function, batched=True)\n",
    "    \n",
    "    # TensorDatasetìœ¼ë¡œ ë³€í™˜\n",
    "    input_ids = np.array(tokenized_train_dataset['input_ids']).astype(np.int64)\n",
    "    attention_mask = np.array(tokenized_train_dataset['attention_mask']).astype(np.int64)\n",
    "    token_type_ids = np.array(tokenized_train_dataset['token_type_ids']).astype(np.int64)\n",
    "    labels = np.array(tokenized_train_dataset['label']).astype(np.int64) \n",
    "    \n",
    "    train_data = TensorDataset(\n",
    "        torch.tensor(input_ids).long(), \n",
    "        torch.tensor(attention_mask).long(), \n",
    "        torch.tensor(token_type_ids).long(), \n",
    "        torch.tensor(labels).long()\n",
    "    )\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        train_data, \n",
    "        sampler=RandomSampler(train_data), \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    # 3. ëª¨ë¸ ë¡œë“œ ë° LoRA ì ìš©\n",
    "    print(f\"\\n[ëª¨ë¸ ë¡œë“œ] ì €ì¥ëœ ëª¨ë¸ '{MODEL_LOAD_PATH}' ë¡œë“œ ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Base Modelì„ ë‹¨ì¼ ì¥ì¹˜ì— ìˆ˜ë™ ë¡œë“œ\n",
    "        base_model = BertForSequenceClassification.from_pretrained(\n",
    "            MODEL_LOAD_PATH, \n",
    "            num_labels=2,\n",
    "            torch_dtype=torch.float32, \n",
    "            return_dict=True           \n",
    "        )\n",
    "    \n",
    "        # 2. LoRA ì„¤ì • ë° ì ìš©\n",
    "        lora_config = LoraConfig(r=8, lora_alpha=16, target_modules=[\"query\", \"key\", \"value\"], \n",
    "                                 lora_dropout=0.05, bias=\"none\", task_type=TaskType.SEQ_CLS)\n",
    "        lora_model = get_peft_model(base_model, lora_config)\n",
    "    \n",
    "        # 3. ëª¨ë¸ì„ ìµœì¢… í•™ìŠµ ì¥ì¹˜ë¡œ ì´ë™\n",
    "        lora_model.to(DEVICE)\n",
    "        print(\"âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ë° ë‹¨ì¼ ì¥ì¹˜ ì´ë™ ì„±ê³µ.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì¹˜ëª…ì ì¸ ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "    print(\"--- LoRA ì ìš© ëª¨ë¸ ì •ë³´ ---\")\n",
    "    lora_model.print_trainable_parameters()\n",
    "    \n",
    "    # 4. ì˜µí‹°ë§ˆì´ì € ì„¤ì • (ìˆ˜ë™)\n",
    "    optimizer = torch.optim.AdamW(lora_model.parameters(), lr=2e-5, eps=1e-8)\n",
    "    \n",
    "    # 5. ìˆ˜ë™ í•™ìŠµ ë£¨í”„ ì‹œì‘\n",
    "    total_t0 = time.time()\n",
    "    \n",
    "    for epoch_i in range(0, epochs):\n",
    "        print(f\"\\n======== Epoch {epoch_i + 1} / {epochs} ========\")\n",
    "        print('Training...')\n",
    "\n",
    "        t0 = time.time()\n",
    "        lora_model.train()\n",
    "        \n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training\")):\n",
    "            \n",
    "            try:\n",
    "                # í…ì„œ GPU ì´ë™\n",
    "                b_input_ids, b_input_mask, b_token_type_ids, b_labels = batch\n",
    "                \n",
    "                b_input_ids = b_input_ids.to(DEVICE)\n",
    "                b_input_mask = b_input_mask.to(DEVICE)\n",
    "                b_token_type_ids = b_token_type_ids.to(DEVICE)\n",
    "                b_labels = b_labels.to(DEVICE) \n",
    "                \n",
    "                lora_model.zero_grad()\n",
    "\n",
    "                outputs = lora_model(\n",
    "                    b_input_ids, \n",
    "                    token_type_ids=b_token_type_ids, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "\n",
    "                # ì—­ì „íŒŒ ë° ìµœì í™”\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(lora_model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            except Exception as e:\n",
    "                # ğŸš¨ ì—ëŸ¬ ë°œìƒ ì‹œ ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ ğŸš¨\n",
    "                print(\"\\n\\n\" + \"=\"*80)\n",
    "                print(f\"ğŸš¨ğŸš¨ğŸš¨ ëŸ°íƒ€ì„/CUDA ì—ëŸ¬ ë°œìƒ: {e} ğŸš¨ğŸš¨ğŸš¨\")\n",
    "                print(f\"ğŸš¨ ì—ëŸ¬ ë°œìƒ ì§€ì : Epoch {epoch_i + 1}, Step {step}, Batch Size: {batch_size}\")\n",
    "                print(f\"\\n[ë””ë²„ê¹… ì •ë³´ - ë ˆì´ë¸” í™•ì¸]\")\n",
    "                print(f\"ë°°ì¹˜ ë ˆì´ë¸”(CPU): {b_labels.cpu().tolist()}\")\n",
    "                print(f\"ë°°ì¹˜ ë ˆì´ë¸” ìµœì†Œ/ìµœëŒ€ê°’: {b_labels.min().item()} / {b_labels.max().item()}\")\n",
    "                print(\"=\"*80 + \"\\n\")\n",
    "                \n",
    "                return lora_model \n",
    "\n",
    "        print(f\"Epoch {epoch_i + 1} Training Time: {format_time(time.time() - t0)}\")\n",
    "        \n",
    "    print(\"\\nTraining complete! (ìˆ˜ë™ ë£¨í”„)\")\n",
    "    \n",
    "    # 6. í›ˆë ¨ëœ LoRA ì–´ëŒ‘í„° ì €ì¥\n",
    "    print(f\"\\n=== 6. LoRA ì–´ëŒ‘í„° ì €ì¥ ===\")\n",
    "    lora_model.save_pretrained(save_path)\n",
    "    print(f\"âœ… LoRA ì–´ëŒ‘í„°ê°€ '{save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    return lora_model\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 5. ëª¨ë¸ ì¶”ë¡  ë° ìœ í˜•ë³„ í‰ê°€ í•¨ìˆ˜ ì¶”ê°€ (ìˆ˜ì •: ì½¤ë§ˆ ë¶„ë¦¬ ë¡œì§ ì ìš©)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def inference_and_evaluate(lora_save_path, test_csv_path, batch_size=32):\n",
    "    \n",
    "    if not os.path.exists(lora_save_path):\n",
    "        print(f\"ê²½ê³ : LoRA ì–´ëŒ‘í„° ê²½ë¡œ '{lora_save_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # 1. GPU ë° í™˜ê²½ ì„¤ì •\n",
    "    if torch.cuda.is_available():\n",
    "        DEVICE = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        DEVICE = torch.device(\"cpu\")\n",
    "    print(f\"\\n\\n=== ğŸ§ª ì¶”ë¡  ë° í‰ê°€ ì‹œì‘ ===\")\n",
    "    print(f\"**ìµœì¢… ì¶”ë¡  ì¥ì¹˜**: {DEVICE}\")\n",
    "    \n",
    "    # 2. Base Model ë¡œë“œ ë° LoRA ì–´ëŒ‘í„° ì ìš©\n",
    "    try:\n",
    "        base_model = BertForSequenceClassification.from_pretrained(\n",
    "            MODEL_LOAD_PATH, \n",
    "            num_labels=2,\n",
    "            return_dict=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Base Model ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "    \n",
    "    lora_model = PeftModel.from_pretrained(base_model, lora_save_path)\n",
    "    lora_model.eval() \n",
    "    lora_model.to(DEVICE)\n",
    "    print(\"âœ… LoRA ì–´ëŒ‘í„°ê°€ Base Modelì— ì„±ê³µì ìœ¼ë¡œ ë³‘í•©ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # 3. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° í† í¬ë‚˜ì´ì§•\n",
    "    try:\n",
    "        test_dataset_hf, original_types = load_and_preprocess_data(\n",
    "            test_csv_path, is_training=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ/ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "        \n",
    "    tokenized_test_dataset = test_dataset_hf.map(tokenize_function, batched=True)\n",
    "    \n",
    "    # 4. DataLoader ì¤€ë¹„\n",
    "    test_input_ids = torch.tensor(tokenized_test_dataset['input_ids']).long()\n",
    "    test_attention_mask = torch.tensor(tokenized_test_dataset['attention_mask']).long()\n",
    "    test_token_type_ids = torch.tensor(tokenized_test_dataset['token_type_ids']).long()\n",
    "    test_labels = torch.tensor(tokenized_test_dataset['label']).long()\n",
    "    \n",
    "    test_data = TensorDataset(test_input_ids, test_attention_mask, test_token_type_ids, test_labels)\n",
    "    test_dataloader = DataLoader(\n",
    "        test_data, \n",
    "        sampler=SequentialSampler(test_data), \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    # 5. ì¶”ë¡  ë£¨í”„ ì‹¤í–‰\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    print(\"\\n[ì¶”ë¡ ] ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...\")\n",
    "    \n",
    "    for batch in tqdm(test_dataloader, desc=\"Inference\"):\n",
    "        batch = tuple(t.to(DEVICE) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_token_type_ids, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = lora_model(\n",
    "                b_input_ids, \n",
    "                token_type_ids=b_token_type_ids, \n",
    "                attention_mask=b_input_mask\n",
    "            )\n",
    "            \n",
    "        logits = outputs.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        predictions.extend(np.argmax(logits, axis=1).flatten())\n",
    "        true_labels.extend(label_ids.flatten())\n",
    "\n",
    "    # 6. ìœ í˜•ë³„ ê²°ê³¼ ë¶„ì„ (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„)\n",
    "    \n",
    "    # LoRA ì–´ëŒ‘í„° ì ìš©ì´ ì„±ê³µí–ˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„°í”„ë ˆì„ì„ ë‹¤ì‹œ ë¡œë“œí•˜ì—¬\n",
    "    # 'ìœ í˜•' ì»¬ëŸ¼ì„ ì•ˆì „í•˜ê²Œ ë¶„ë¦¬í•©ë‹ˆë‹¤. (ì •ì œëœ ë°ì´í„°ì˜ ë§µí•‘ì„ ì‚¬ìš©)\n",
    "    \n",
    "    # ì •ì œ í›„ ë‚¨ì€ ë°ì´í„°í”„ë ˆì„ êµ¬ì¡°ë¥¼ ë³µì›\n",
    "    results_df = pd.DataFrame({\n",
    "        'type': original_types[:len(true_labels)], # ì •ì œ í›„ ë‚¨ì€ ë°ì´í„°ë§Œí¼ë§Œ ì‚¬ìš©\n",
    "        'true_label': true_labels,\n",
    "        'prediction': predictions\n",
    "    })\n",
    "    \n",
    "    # ğŸŒŸğŸŒŸğŸŒŸ ìœ í˜• ì»¬ëŸ¼ì„ ì½¤ë§ˆ(,)ë¡œ ë¶„ë¦¬í•˜ê³  ëª¨ë“  ê³ ìœ  ìœ í˜•ì„ ì¶”ì¶œ ğŸŒŸğŸŒŸğŸŒŸ\n",
    "    all_types = set()\n",
    "    results_df['type'].astype(str).str.split(',').apply(all_types.update)\n",
    "    all_types.discard('nan')\n",
    "    \n",
    "    print(\"\\n\\n=== ğŸ“Š ë‹¤ì¤‘ ìœ í˜•ë³„ ë¶„ë¥˜ ê²°ê³¼ (ì½¤ë§ˆ ë¶„ë¦¬) ===\")\n",
    "    \n",
    "    # ì „ì²´ ë³´ê³ ì„œ\n",
    "    print(\"\\n[ì „ì²´ ë°ì´í„°ì…‹ ë¶„ë¥˜ ë³´ê³ ì„œ]\")\n",
    "    print(classification_report(results_df['true_label'], results_df['prediction'], \n",
    "                                target_names=['ë¹„ë„ë•ì„± ì—†ìŒ (0)', 'ë¹„ë„ë•ì„± ìˆìŒ (1)']))\n",
    "    \n",
    "    # ğŸŒŸ ìœ í˜•ë³„ ë³´ê³ ì„œ (ê° ìœ í˜•ì— í•´ë‹¹ë˜ëŠ” ìƒ˜í”Œë§Œ í‰ê°€)\n",
    "    for type_name in sorted(list(all_types)):\n",
    "        \n",
    "        # í˜„ì¬ type_nameì„ í¬í•¨í•˜ëŠ” í–‰ë§Œ í•„í„°ë§\n",
    "        group = results_df[results_df['type'].astype(str).str.contains(type_name)].reset_index(drop=True)\n",
    "        \n",
    "        if len(group) == 0:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n--- [ìœ í˜•ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼] ìœ í˜•: {type_name} ---\")\n",
    "        print(f\"ì´ ìƒ˜í”Œ ìˆ˜: {len(group):,}\")\n",
    "        \n",
    "        try:\n",
    "            report = classification_report(group['true_label'], group['prediction'], \n",
    "                                           target_names=['ë¹„ë„ë•ì„± ì—†ìŒ (0)', 'ë¹„ë„ë•ì„± ìˆìŒ (1)'], \n",
    "                                           output_dict=False, zero_division=0)\n",
    "            print(report)\n",
    "        except ValueError as e:\n",
    "            print(f\"ê²½ê³ : {type_name}ì—ì„œ í‰ê°€ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            \n",
    "    print(\"================================\")\n",
    "    print(\"âœ… ë‹¤ì¤‘ ìœ í˜•ë³„ ì¶”ë¡  ë° í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 6. ë©”ì¸ ì‹¤í–‰ë¶€\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        # 1. ëª¨ë¸ í›ˆë ¨ ë° LoRA ì–´ëŒ‘í„° ì €ì¥\n",
    "        final_model = debug_lora_training(epochs=3, batch_size=8)\n",
    "        \n",
    "        if final_model is not None:\n",
    "            print(\"\\nëª¨ë“  í›ˆë ¨ ë° ì €ì¥ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "            # 2. í›ˆë ¨ëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ë¡  ë° ìœ í˜•ë³„ í‰ê°€ ìˆ˜í–‰\n",
    "            inference_and_evaluate(\n",
    "                lora_save_path=LORA_SAVE_PATH,\n",
    "                test_csv_path=TEST_DATA_PATH,\n",
    "                batch_size=32 \n",
    "            )\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nìµœì¢… ì‹¤í–‰ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ff421-96ed-4fa8-8ba8-dc65dd612e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
